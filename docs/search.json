[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini-Project #01: NYC Payroll Analysis",
    "section": "",
    "text": "Executive Summary:\nThe following analysis utilizes the NYC payroll data to examine payroll trends, identify key figures within the dataset, and evaluate three potential policy proposals:\n\nCapping salaries at the mayoral level.\nIncreasing staffing to reduce overtime expenses.\nImplementing a performance-based pay structure.\n\nThe goal is to understand potential savings, key individuals, agencies, and trends in the city’s payroll system. Each policy is analyzed in terms of its financial impact, implementation feasibility, and potential issues on workforce moral and performance.\n\n\n\nIntroduction:\nThe City of New York spends significant amounts on payroll across various departments, with substantial portions allocated to overtime pay and high-level salaries. In an effort to address growing payroll expenses, three potential policy initiatives have been explored in this report. These policies are intended to reduce costs, increase efficiency, and ensure fairness within the payroll structure, all while maintaining employee motivation and performance.\n\n\n\nData Collection and Preparation:\nThe dataset used for this analysis derives from the NYC payroll system. This data is collected in batches using the NYC’s open data platform, where:\n\nFile Formate: The data is in CVS format, reperesenting city payroll records, including employee names, positions, salaries and compensations, and other related details.\nData Processing: Various libraries (e.g., dplyr, jsonlite, httr2, readr, stringr, DT, and scales) are used to clean and process the data.\n\nKey insights drawn from the data include:\n\nEmployee Compensation: Calculations of total compensation for key individuals, including salaries, ovetime pay, and other compensations.\nAggregated Salaries: Analysis of city-wide payroll figures, employee counts, and overtime statistics.\n\n\n\n\nKey Insights from NYC Payroll Data:\n\nTop Paid Individual: The highest city total payroll (regular salary + overtime pay) for a single individual is identified.\nOvertime Trends: The individual with the most overtime hours and the agency with the highest overtime usage are highlighted.\nHighest Paying Agencies: The agency with the highest average total payroll per employee is identified.\nPayroll Growth: Over the past 10 years, the city’s aggregate payroll has grown, with the trend showcasing the need for cost control measure.\n\n\n\n\nPolicy Proposals:\n\nPolicy 1: Capping Salaries at the Mayoral Level\n\nObjective: To limit compensation of city employees to the mayor’s total pay, as a mean to reduce government spending.\nAnalysis:\n\nThe mayor’s salary is calculated by summing his regular pay and overtime for each fiscal year.\nEmployees earning above the mayor’s salary are identified, and their salary reductios are computed by deducting the mayor’s salary from their total pay.\nA benchmark of $10 million in savings was administrated to determine whether the proposal would have significant impact.\nPotential Savings: The total savings from implementing this policy is approximately $3.4 billion. Agencies, such as Department of Pedagogical, Fire Department, and Police Department would bear the brunt of the salary caps.\n\nRecommendation: While the policy could yield total savings exceeding $10 million, it may affect employee morale (e.g., lack of motivation), especially amonst high-level positions. Consideration should be given to alternative savings strategies that target overtime reduction.\n\n\n\nPolicy 2: Increasing Staffing to Reduce Overtime Expenses\n\nObjectives: To reduce the need for overtime by increasing the number of full-time employees in key agencies.\nAnalysis:\n\nOvertime data is analyzed across various agencies, with an estimate of the number of full-time employees needed to replace overtime.\nCost Comparison: The cost of overtime is compared to the potential cost of hiring full-time employees to replace overtime hours.\nSavings Potential: Agencies with the higher overtime costs could save significant amounts by replacing overtime with regular employees.\n\nRecommendation: This policy has the potential for substantial savings, especial in agencies with significant overtime costs. The financial viability of this approach should be further explored with specific focus on high overtime usage agencies.\n\n\n\nPolicy 3: Implementing a Performance-Based Pay Structure\n\nObjective: Introduce a performance-based pay structure where employees are rewarded based on their performance, including task completion, complaints received, and response times.\nAnalysis:\n\nA sample employee dataset is used to create performance-based pay by introducing bonuses for task completion and penalties for complaints. In this case, a 10% bonus is introduced for exceeding 100 tasks and a 5% reduction penalty is calculated for 3+ complaints. The performance is calculated by taking the difference of the bonus and the penalty.\nThe total cost of payroll before and after implementing the performance-based pay structure is compared.\nPotential Savings: By adjusting compensation based on performance, savings are realized in the form of reduced pay for low-performing employees. A total savings of $1.2 million is approximating amongst the Health, the Police, and the Public Works departments.\nVisualization: A boxplot is provided to visualize how compensation would change across agencies under the new pay structure.\n\n\n\n\nRecommendation: This policy could lead to some cost savings, particularly for underperforming employees. However, careful consideration of performance metrics and employee buy-in is needed to ensure effectiveness and fairness in the system.\n\n\n\n\n\nSummary of Findings and Recommendations\n\nCapping Salaries: Potential savings from capping salaries at the mayoral level could be substantial. However, the policy risks significant morale impacts among higher-paid employees. A balance between cost-saving and employee satisfaction should be considered.\nIncreasing Staffing: This proposal could reduce overtime-related expenses significantly, especially for agencies with the highest overtime usage. Further analysis is needed on the recruitment and training costs associated with increasing staffing levels.\nPerformance-Based Pay: Implementing a performance-based pay structure could encourage higher productivity but requires careful planning to ensure fairness and avoid unintended consequences, such as employee dissatisfaction.\n\n\n\n\nConclusion:\nAll three policy proposals offer potential solutions to manage NYC’s growing payroll expenses. However, each comes with its own set of challenges and considerations. A detailed cost-benefit analysis, alongside employee feedback, will be crucial in selecting the most viable strategy. Further testing and pilot programs are recommended before widespread implementation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chenbin Wu",
    "section": "",
    "text": "Hi, I am Chenbin Wu, currently a Graduate student at Baruch College studying Business Analytics and concentrating in Data Analytics.\nHere is a link to my LinkedIn.jhiu\n\nLast Updated: Thursday 03 06, 2025 at 00:29AM"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini-Project #02: Identifying Environmentally Responsible US Public Transit Systems",
    "section": "",
    "text": "Press Release: ‘Greenest’ Transit Agency of the Year Award\n\nExecutive Summary:\nNew York, NY – March 26, 2025 – In efforts to recognize transit agencies demonstrating exceptional efficiency and sustainability, Green Transit Alliance for Investigation of Variance (GTA IV) is proud to announce the winners of the ‘Greenest’ Transit Agencies awards. These awards are based on an in-dept analysis of public transit data, evaluating agencies across key performance metrics including fuel efficiency, emissions reduction, and operational effectiveness.\n\n\n\n\nAppendix: Analysis and Methodology\n\nIntroduction: \nThis appendix outlines the methodology and metrics used to identify the ‘Greenest’ Transit Agency of the Year Award winners. The selection process involves a detailed review of several key factors such as fuel consumption, emissions per mile, and total operational emissions across various transit systems.\n\n\nData Collection and Analysis:\nData was collected from the following sources:\n- Agency reports and annual performance reviews.\n- Publicly available transit data sets, including the National Transit Database.\n- Customer satisfaction surveys and feedback from various transit agencies.\nData was cleaned and processed for analysis.\n\n\nShow the code\nensure_package &lt;- function(pkg){\n  pkg &lt;- as.character(substitute(pkg))\n  options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n  if(!require(pkg, character.only=TRUE)) install.packages(pkg)\n  stopifnot(require(pkg, character.only=TRUE))\n}\n\nensure_package(dplyr)\nensure_package(httr2)\nensure_package(rvest)\nensure_package(datasets)\nensure_package(purrr)\nensure_package(DT)\nensure_package(stringr)\n\n\nget_eia_sep &lt;- function(state, abbr){\n  state_formatted &lt;- str_to_lower(state) |&gt; str_replace_all(\"\\\\s\", \"\")\n  \n  dir_name &lt;- file.path(\"data\", \"mp02\")\n  file_name &lt;- file.path(dir_name, state_formatted)\n  \n  dir.create(dir_name, showWarnings=FALSE, recursive=TRUE)\n  \n  if(!file.exists(file_name)){\n    BASE_URL &lt;- \"https://www.eia.gov\"\n    REQUEST &lt;- request(BASE_URL) |&gt; \n      req_url_path(\"electricity\", \"state\", state_formatted)\n    \n    RESPONSE &lt;- req_perform(REQUEST)\n    \n    resp_check_status(RESPONSE)\n    \n    writeLines(resp_body_string(RESPONSE), file_name)\n  }\n  \n  TABLE &lt;- read_html(file_name) |&gt; \n    html_element(\"table\") |&gt; \n    html_table() |&gt;\n    mutate(Item = str_to_lower(Item))\n  \n  if(\"U.S. rank\" %in% colnames(TABLE)){\n    TABLE &lt;- TABLE |&gt; rename(Rank = `U.S. rank`)\n  }\n  \n  CO2_MWh &lt;- TABLE |&gt; \n    filter(Item == \"carbon dioxide (lbs/mwh)\") |&gt;\n    pull(Value) |&gt; \n    str_replace_all(\",\", \"\") |&gt;\n    as.numeric()\n  \n  PRIMARY &lt;- TABLE |&gt; \n    filter(Item == \"primary energy source\") |&gt; \n    pull(Rank)\n  \n  RATE &lt;- TABLE |&gt;\n    filter(Item == \"average retail price (cents/kwh)\") |&gt;\n    pull(Value) |&gt;\n    as.numeric()\n  \n  GENERATION_MWh &lt;- TABLE |&gt;\n    filter(Item == \"net generation (megawatthours)\") |&gt;\n    pull(Value) |&gt;\n    str_replace_all(\",\", \"\") |&gt;\n    as.numeric()\n  \n  data.frame(CO2_MWh               = CO2_MWh, \n             primary_source        = PRIMARY,\n             electricity_price_MWh = RATE * 10, # / 100 cents to dollars &\n             # * 1000 kWh to MWH \n             generation_MWh        = GENERATION_MWh, \n             state                 = state, \n             abbreviation          = abbr\n  )\n}\n\nEIA_SEP_REPORT &lt;- map2(state.name, state.abb, get_eia_sep) |&gt; list_rbind()\n\n\nData was collected using the U.S. Energy Information Administration’s website. The primary data metrics were based on emissions per MWh of electricity produced, and the total generation capacity was cross-checked with state-level reports.\nAs you can see below, the effective emissions per MWh and total state-wide generation capacity are shown.\n\n\nShow the code\nensure_package(scales)\nensure_package(DT)\n\nEIA_SEP_REPORT |&gt; \n  select(-abbreviation) |&gt;\n  arrange(desc(CO2_MWh)) |&gt;\n  mutate(CO2_MWh = number(CO2_MWh, big.mark=\",\"), \n         electricity_price_MWh = dollar(electricity_price_MWh), \n         generation_MWh = number(generation_MWh, big.mark=\",\")) |&gt;\n  rename(`Pounds of CO2 Emitted per MWh of Electricity Produced`=CO2_MWh, \n         `Primary Source of Electricity Generation`=primary_source, \n         `Average Retail Price for 1000 kWh`=electricity_price_MWh, \n         `Total Generation Capacity (MWh)`= generation_MWh, \n         State=state) |&gt;\n  datatable()\n\n\n\n\n\n\nThe following exploratory questions helped analyze the environmental impact of each state’s electricity mix:\n\n\n\n\n\n\nAnalysis of SEP Data\n\n\n\n1. Which state has the most expensive retail electricity?\n- Hawaii leads with the highest electricity cost of $386/MWh.\n\n\nShow the code\nEIA_SEP_REPORT |&gt; \n  select(state, electricity_price_MWh) |&gt;\n  arrange(desc(electricity_price_MWh)) |&gt;\n  head(1)\n\n\n   state electricity_price_MWh\n1 Hawaii                   386\n\n\n2. Which state has the ‘dirtiest’ electricity mix?\n- West Virginia shows the highest CO2 emissions per MWh of 1,925 lbs.\n\n\nShow the code\nEIA_SEP_REPORT |&gt; \n  select(state, CO2_MWh) |&gt;\n  arrange(desc(CO2_MWh)) |&gt;\n  head(1)\n\n\n          state CO2_MWh\n1 West Virginia    1925\n\n\n3. On average, how many pounds of CO2 are emitted per MWh of electricity produced in the US?\n- The weighted average CO2 emissions per MWh for the U.S. is 805.37 lbs.\n\n\nShow the code\nweighted_avg_CO2 &lt;- sum(EIA_SEP_REPORT$CO2_MWh * EIA_SEP_REPORT$generation_MWh, na.rm = TRUE) / \n  sum(EIA_SEP_REPORT$generation_MWh, na.rm = TRUE)\nweighted_avg_CO2\n\n\n[1] 805.3703\n\n\n4. What is the rarest primary energy source in the US? What is the associated cost of electricity and where is it used? \n- Petroleum is the rarest energy source used, particularly in Hawaii, with a cost of $386/MWh.\n\n\nShow the code\nenergy_counts &lt;- table(EIA_SEP_REPORT$primary_source)\n\nrarest_energy_source &lt;- names(energy_counts)[which.min(energy_counts)]\n\nrarest_states &lt;- EIA_SEP_REPORT |&gt;\n  filter(primary_source == rarest_energy_source)\n \nrarest_info &lt;- rarest_states |&gt;\n  select(state, electricity_price_MWh, primary_source)\n\nrarest_info\n\n\n   state electricity_price_MWh primary_source\n1 Hawaii                   386      Petroleum\n\n\n5. My home state, Texas, has a reputation as being the home of “dirty fossil fuels” while NY has a reputation as a leader in clean energy. How many times cleaner is NY’s energy mix than that of Texas?\n- New York’s energy mix is 1.64 times cleaner than Texas’s.\n\n\nShow the code\nny_co2 &lt;- EIA_SEP_REPORT |&gt;\n  filter(state == \"New York\") |&gt;\n  pull(CO2_MWh)\n\ntx_co2 &lt;- EIA_SEP_REPORT |&gt;\n  filter(state == \"Texas\") |&gt;\n  pull(CO2_MWh)\n\n# Calculate how many times cleaner NY is than TX\ncleanliness_ratio &lt;- tx_co2 / ny_co2\ncleanliness_ratio\n\n\n[1] 1.637931\n\n\n\n\nAnalysis of Public Transit Data: \nPublic transit data was extracted from the National Transit Database (NTD), which includes energy consumption and passenger trip statistics.\n\n\nShow the code\nensure_package(readxl)\n# Create 'data/mp02' directory if not already present\nDATA_DIR &lt;- file.path(\"data\", \"mp02\")\ndir.create(DATA_DIR, showWarnings=FALSE, recursive=TRUE)\n\nNTD_ENERGY_FILE &lt;- file.path(DATA_DIR, \"2023_ntd_energy.xlsx\")\n\nif(!file.exists(NTD_ENERGY_FILE)){\n  DS &lt;- download.file(\"https://www.transit.dot.gov/sites/fta.dot.gov/files/2024-10/2023%20Energy%20Consumption.xlsx\", \n                      destfile=NTD_ENERGY_FILE, \n                      method=\"curl\")\n  \n  if(DS | (file.info(NTD_ENERGY_FILE)$size == 0)){\n    cat(\"I was unable to download the NTD Energy File. Please try again.\\n\")\n    stop(\"Download failed\")\n  }\n}\n\nNTD_ENERGY_RAW &lt;- read_excel(NTD_ENERGY_FILE, na = \"-\")\n\nensure_package(tidyr)\nto_numeric_fill_0 &lt;- function(x){\n  x &lt;- if_else(x == \"-\", NA, x)\n  replace_na(as.numeric(x), 0)\n}\n\nNTD_ENERGY &lt;- NTD_ENERGY_RAW |&gt; \n  select(-c(`Reporter Type`, \n            `Reporting Module`, \n            `Other Fuel`, \n            `Other Fuel Description`)) |&gt;\n  mutate(across(-c(`Agency Name`, \n                   `Mode`,\n                   `TOS`), \n                to_numeric_fill_0)) |&gt;\n  group_by(`NTD ID`, `Mode`, `Agency Name`) |&gt;\n  summarize(across(where(is.numeric), sum), \n            .groups = \"keep\") |&gt;\n  mutate(ENERGY = sum(c_across(c(where(is.numeric))))) |&gt;\n  filter(ENERGY &gt; 0) |&gt;\n  select(-ENERGY) |&gt;\n  ungroup()\n\nNTD_ENERGY &lt;- NTD_ENERGY |&gt;\n  mutate(Mode = case_when(\n    Mode == \"HR\" ~ \"Heavy Rail\", \n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"MB\" ~ \"Motor Bus\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"CB\" ~ \"Cable Car\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"MG\" ~ \"Monorail / Automated Guideway\",\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    TRUE ~ \"Unknown\"\n  ))\n\nensure_package(readr)\nlibrary(readr)\n\nNTD_SERVICE_FILE &lt;- file.path(DATA_DIR, \"2023_service.csv\")\nif(!file.exists(NTD_SERVICE_FILE)){\n  DS &lt;- download.file(\"https://data.transportation.gov/resource/6y83-7vuw.csv\", \n                      destfile=NTD_SERVICE_FILE, \n                      method=\"curl\")\n  \n  if(DS | (file.info(NTD_SERVICE_FILE)$size == 0)){\n    cat(\"I was unable to download the NTD Service File. Please try again.\\n\")\n    stop(\"Download failed\")\n  }\n}\n\nNTD_SERVICE_RAW &lt;- read_csv(NTD_SERVICE_FILE)\n\nNTD_SERVICE &lt;- NTD_SERVICE_RAW |&gt;\n  mutate(`NTD ID` = as.numeric(`_5_digit_ntd_id`)) |&gt; \n  rename(Agency = agency, \n         City   = max_city, \n         State  = max_state,\n         UPT    = sum_unlinked_passenger_trips_upt, \n         MILES  = sum_passenger_miles) |&gt;\n  select(matches(\"^[A-Z]\", ignore.case=FALSE)) |&gt;\n  filter(MILES &gt; 0)\n\n\nAfter cleaning and organizing the data, we focused on the following insights:\n\n\n\n\n\n\nAnalysis of NTD Service Data\n\n\n\n1. Which transit service has the most UPT annually?\n- The MTA from Brooklyn, NY, has the highest UPT annually with 2.63 billion trips.\n\n\nShow the code\nNTD_SERVICE |&gt; \n  arrange(desc(UPT)) |&gt; \n  select(Agency, City, State, UPT) |&gt; \n  head(1)\n\n\n# A tibble: 1 × 4\n  Agency                    City     State        UPT\n  &lt;chr&gt;                     &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;\n1 MTA New York City Transit Brooklyn NY    2632003044\n\n\n2. What is the average trip length of a trip on MTA NYC?\n- The average trip length is 4.56 miles.\n\n\nShow the code\nMTA_NYC &lt;- NTD_SERVICE |&gt; \n  filter(grepl(\"MTA\", Agency, ignore.case = TRUE))\naverage_trip_length &lt;- MTA_NYC |&gt; \n  summarise(avg_trip_length = sum(MILES) / sum(UPT))\naverage_trip_length\n\n\n# A tibble: 1 × 1\n  avg_trip_length\n            &lt;dbl&gt;\n1            4.56\n\n\n3. Which transit service in NYC has the longest average trip length?\n- Private Transportation Corporation has the longest average trip at 5.23 miles.\n\n\nShow the code\nNYC_SERVICES &lt;- NTD_SERVICE |&gt;\n  filter(grepl(\"New York City|Brooklyn\", City, ignore.case = TRUE))\n\navg_trip_length_per_service &lt;- NYC_SERVICES |&gt;\n  group_by(Agency) |&gt;\n  summarise(avg_trip_length = sum(MILES) / sum(UPT)) |&gt;\n  arrange(desc(avg_trip_length))\n\nhead(avg_trip_length_per_service, 1)\n\n\n# A tibble: 1 × 2\n  Agency                             avg_trip_length\n  &lt;chr&gt;                                        &lt;dbl&gt;\n1 Private Transportation Corporation            5.23\n\n\n4. Which state has the fewest total miles travelled by public transit?\n- New Hampshire has the lowest total miles traveled at 3,749,892 miles.\n\n\nShow the code\ntotal_miles_per_state &lt;- NTD_SERVICE |&gt;\n  group_by(State) |&gt;\n  summarise(total_miles = sum(MILES, na.rm = TRUE)) |&gt;\n  arrange(total_miles)\n\nhead(total_miles_per_state, 1)\n\n\n# A tibble: 1 × 2\n  State total_miles\n  &lt;chr&gt;       &lt;dbl&gt;\n1 NH        3749892\n\n\n5. Are all states represented in this data?\n- While all 50 states are represented in the data, some states are missing abbreviations. 21 states are missing abbreviations.\n\n\nShow the code\nstates_in_data &lt;- unique(NTD_SERVICE$State)\n\nmissing_states &lt;- setdiff(state.name, states_in_data)\n\n# Optionally, also check for missing state abbreviations\nmissing_abbr &lt;- setdiff(state.abb, unique(NTD_SERVICE$State))\n\nmissing_states\n\n\n [1] \"Alabama\"        \"Alaska\"         \"Arizona\"        \"Arkansas\"      \n [5] \"California\"     \"Colorado\"       \"Connecticut\"    \"Delaware\"      \n [9] \"Florida\"        \"Georgia\"        \"Hawaii\"         \"Idaho\"         \n[13] \"Illinois\"       \"Indiana\"        \"Iowa\"           \"Kansas\"        \n[17] \"Kentucky\"       \"Louisiana\"      \"Maine\"          \"Maryland\"      \n[21] \"Massachusetts\"  \"Michigan\"       \"Minnesota\"      \"Mississippi\"   \n[25] \"Missouri\"       \"Montana\"        \"Nebraska\"       \"Nevada\"        \n[29] \"New Hampshire\"  \"New Jersey\"     \"New Mexico\"     \"New York\"      \n[33] \"North Carolina\" \"North Dakota\"   \"Ohio\"           \"Oklahoma\"      \n[37] \"Oregon\"         \"Pennsylvania\"   \"Rhode Island\"   \"South Carolina\"\n[41] \"South Dakota\"   \"Tennessee\"      \"Texas\"          \"Utah\"          \n[45] \"Vermont\"        \"Virginia\"       \"Washington\"     \"West Virginia\" \n[49] \"Wisconsin\"      \"Wyoming\"       \n\n\nShow the code\nmissing_abbr\n\n\n [1] \"AZ\" \"AR\" \"CA\" \"CO\" \"HI\" \"IA\" \"KS\" \"LA\" \"MO\" \"MT\" \"NE\" \"NV\" \"NM\" \"ND\" \"OK\"\n[16] \"SD\" \"TX\" \"UT\" \"WY\"\n\n\n\n\n\n\nFinal Analysis:\nThe data analysis involves merging the NTD public transit data with the energy data to assess the environmental impact of each transit agency’s fuel consumption. Each agency is then scored based on their emissions per mile and overall energy consumption, identifying the most sustainable transit systems.\n\n\nShow the code\n# Step 1: Join the tables. Join NTD_SERVICE with NTD_ENERGY by State and Mode\ncombined_data &lt;- NTD_SERVICE |&gt; \n  left_join(NTD_ENERGY, by = c(\"NTD ID\" = \"NTD ID\", \"Agency\" = \"Agency Name\")) |&gt; \n  left_join(EIA_SEP_REPORT, by = c(\"State\" = \"state\"))\n\n# Step 2: Align fuel sources\nbined_data &lt;- combined_data |&gt; \n  mutate(Fuel_Type = case_when(\n    `Bio-Diesel` &gt; 0 ~ \"Bio-Diesel\",\n    `Bunker Fuel` &gt; 0 ~ \"Bunker Fuel\",\n    `C Natural Gas` &gt; 0 ~ \"C Natural Gas\",\n    `Diesel Fuel` &gt; 0 ~ \"Diesel Fuel\",\n    `Electric Battery` &gt; 0 ~ \"Electric Battery\",\n    `Electric Propulsion` &gt; 0 ~ \"Electric Propulsion\",\n    Ethanol &gt; 0 ~ \"Ethanol\",\n    Methonal &gt; 0 ~ \"Methonal\",\n    Gasoline &gt; 0 ~ \"Gasoline\",\n    Hydrogen &gt; 0 ~ \"Hydrogen\",\n    `Liquified Nat Gas` &gt; 0 ~ \"Liquified Nat Gas\",\n    `Liquified Petroleum Gas` &gt; 0 ~ \"Liquified Petroleum Gas\",\n    TRUE ~ \"Other\"  # If no fuel source is present, categorize it as \"Other\"\n  ))\n\n# Step 3: Calculate CO2 emissions\ncombined_data &lt;- bined_data |&gt; \n  mutate(\n    emissions_per_MWh = case_when(\n      Fuel_Type == \"Coal\" ~ 1.925,    \n      Fuel_Type == \"Natural Gas\" ~ 1.180,\n      Fuel_Type == \"Hydroelectric\" ~ 0,  \n      Fuel_Type == \"Wind\" ~ 0,         \n      Fuel_Type == \"Solar\" ~ 0,        \n      Fuel_Type == \"Electric Battery\" ~ 0.02, \n      Fuel_Type == \"Electric Propulsion\" ~ 0.01, \n      TRUE ~ 0                           \n    ),\n    \n    energy_per_mile = case_when(\n      Fuel_Type == \"Coal\" ~ 0.25,      \n      Fuel_Type == \"Natural Gas\" ~ 0.20,\n      Fuel_Type == \"Hydroelectric\" ~ 0,  \n      Fuel_Type == \"Wind\" ~ 0,    \n      Fuel_Type == \"Solar\" ~ 0,         \n      Fuel_Type == \"Electric Battery\" ~ 0.15, \n      Fuel_Type == \"Electric Propulsion\" ~ 0.10, \n      TRUE ~ 0                           \n    ),\n    \n    total_emissions = emissions_per_MWh * energy_per_mile * MILES\n  )\n\n# Output the final table\nfinal_table &lt;- combined_data |&gt; \n  select(Agency, Mode, State, Fuel_Type, emissions_per_MWh, total_emissions)\n\n\n\n\nShow the code\n#Which agencies are most efficient on per UPT and per passenger mile bases?\nagency_emissions &lt;- combined_data |&gt; \n  group_by(Agency, State) |&gt; \n  summarise(\n    total_emissions = sum(total_emissions, na.rm = TRUE),\n    total_UPT = sum(UPT, na.rm = TRUE),\n    total_miles = sum(MILES, na.rm = TRUE)\n  )\n\nagency_emissions &lt;- agency_emissions |&gt; \n  mutate(\n    emissions_per_UPT = total_emissions / total_UPT,\n    emissions_per_mile = total_emissions / total_miles\n  )\n\nagency_emissions_filtered &lt;- agency_emissions |&gt; \n  filter(total_UPT &gt; 10000) \n\nagency_emissions_filtered &lt;- agency_emissions_filtered |&gt; \n  mutate(\n    agency_size = case_when(\n      total_UPT &lt; 50000 ~ \"Small\",\n      total_UPT &gt;= 50000 & total_UPT &lt; 500000 ~ \"Medium\",\n      total_UPT &gt;= 500000 ~ \"Large\",\n      TRUE ~ \"Unknown\"\n    )\n  )\n\nmost_efficient_small &lt;- agency_emissions_filtered |&gt; \n  filter(agency_size == \"Small\") |&gt; \n  arrange(emissions_per_UPT) |&gt; \n  top_n(-1, emissions_per_UPT)\nmost_efficient_small\n\n\n# A tibble: 6 × 8\n# Groups:   Agency [6]\n  Agency           State total_emissions total_UPT total_miles emissions_per_UPT\n  &lt;chr&gt;            &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n1 County of Dougl… GA                  0     49871      333837                 0\n2 North Central A… AL                  0     38312      206786                 0\n3 Regional Planni… AL                  0     40045     2357836                 0\n4 Rhode Island De… RI                  0     34821      904702                 0\n5 Southwestern Pe… PA                  0     22169      758063                 0\n6 Valley Transit … CT                  0     48819      277875                 0\n# ℹ 2 more variables: emissions_per_mile &lt;dbl&gt;, agency_size &lt;chr&gt;\n\n\nShow the code\nmost_efficient_medium &lt;- agency_emissions_filtered |&gt; \n  filter(agency_size == \"Medium\") |&gt; \n  arrange(emissions_per_UPT) |&gt; \n  top_n(-1, emissions_per_UPT)\nmost_efficient_medium\n\n\n# A tibble: 62 × 8\n# Groups:   Agency [62]\n   Agency          State total_emissions total_UPT total_miles emissions_per_UPT\n   &lt;chr&gt;           &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n 1 Ada County Hig… ID                  0    130715     5076885                 0\n 2 Adirondack Tra… NY                  0    362745    31065245                 0\n 3 Alaska Railroa… AK                  0    225434    27930710                 0\n 4 Altoona Metro … PA                  0    444716     1614732                 0\n 5 Anne Arundel C… MD                  0    299714     2304500                 0\n 6 Audubon Area C… KY                  0    132537     2512446                 0\n 7 Augusta Richmo… GA                  0    423982     1726132                 0\n 8 Baldwin County… AL                  0    101576     1077003                 0\n 9 Bay County Tra… FL                  0    398400     2792272                 0\n10 Bay Metropolit… MI                  0    290244     2107127                 0\n# ℹ 52 more rows\n# ℹ 2 more variables: emissions_per_mile &lt;dbl&gt;, agency_size &lt;chr&gt;\n\n\nShow the code\nmost_efficient_large &lt;- agency_emissions_filtered |&gt; \n  filter(agency_size == \"Large\") |&gt; \n  arrange(emissions_per_UPT) |&gt; \n  top_n(-1, emissions_per_UPT)\n\nmost_efficient_large\n\n\n# A tibble: 233 × 8\n# Groups:   Agency [233]\n   Agency          State total_emissions total_UPT total_miles emissions_per_UPT\n   &lt;chr&gt;           &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n 1 Academy Lines,… NJ                  0   1064165    44972754                 0\n 2 Alternativa de… PR                  0   3732115    15671639                 0\n 3 Ann Arbor Area… MI                  0  18722260    94480960                 0\n 4 Arlington Coun… VA                  0   2097034     5273946                 0\n 5 Athens-Clarke … GA                  0   1186787     4197292                 0\n 6 Atlanta-Region… GA                  0   1690548    55477910                 0\n 7 Beaver County … PA                  0    923424     7243688                 0\n 8 Ben Franklin T… WA                  0   9535131    72976146                 0\n 9 Berkshire Regi… MA                  0   1019928     6109646                 0\n10 Birmingham-Jef… AL                  0   5387286    27996114                 0\n# ℹ 223 more rows\n# ℹ 2 more variables: emissions_per_mile &lt;dbl&gt;, agency_size &lt;chr&gt;\n\n\n\n\n\n\nAwards\n1. Greenest Transit Agency (lowest emissions per UPT) Award: This award is based on the agency with the lowest emissions per UPT, emphasizing efficiency in reducing emissions per passenger.\n\n\nShow the code\ngreenest_agency &lt;- agency_emissions_filtered |&gt; \n  arrange(emissions_per_UPT) |&gt; \n  top_n(-1, emissions_per_UPT)  \ngreenest_agency\n\n\n# A tibble: 301 × 8\n# Groups:   Agency [301]\n   Agency          State total_emissions total_UPT total_miles emissions_per_UPT\n   &lt;chr&gt;           &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n 1 Academy Lines,… NJ                  0   1064165    44972754                 0\n 2 Ada County Hig… ID                  0    130715     5076885                 0\n 3 Adirondack Tra… NY                  0    362745    31065245                 0\n 4 Alaska Railroa… AK                  0    225434    27930710                 0\n 5 Alternativa de… PR                  0   3732115    15671639                 0\n 6 Altoona Metro … PA                  0    444716     1614732                 0\n 7 Ann Arbor Area… MI                  0  18722260    94480960                 0\n 8 Anne Arundel C… MD                  0    299714     2304500                 0\n 9 Arlington Coun… VA                  0   2097034     5273946                 0\n10 Athens-Clarke … GA                  0   1186787     4197292                 0\n# ℹ 291 more rows\n# ℹ 2 more variables: emissions_per_mile &lt;dbl&gt;, agency_size &lt;chr&gt;\n\n\nShow the code\nlibrary(ggplot2)\n\n# Greenest Transit Agency visualization\nggplot(agency_emissions_filtered, aes(x = Agency, y = emissions_per_mile)) +\n  geom_bar(stat = \"identity\", fill = \"green\") +\n  theme_minimal() +\n  labs(title = \"Emissions per Passenger Mile (Greenest Transit Agencies)\", \n       x = \"Agency\", y = \"Emissions (lbs CO2/mile)\")\n\n\n\n\n\n\n\n\n\nShow the code\n# Agency with the lowest emissions per UPT\n\n\n2. Most Emissions Avoided Award: This award identifies the agency with the highest amount of avoided emissions by comparing transit emissions to car emissions (calculated using the CAFE standard).\n\n\nShow the code\n# Task 2: Most Emissions Avoided (comparison to car emissions)\n# Assuming CAFE standard of 24.2 miles per gallon and emissions factor of 8.89 kg CO2 per gallon\nCAFE_mpg &lt;- 24.2\nemissions_factor_per_gallon &lt;- 8.89  # kg CO2 per gallon\n\n# Calculate emissions from driving (per mile)\ndriving_emissions_per_mile &lt;- (1 / CAFE_mpg) * emissions_factor_per_gallon * 1000  # kg CO2 per mile\n\n# Calculate avoided emissions\nagency_emissions_filtered &lt;- agency_emissions_filtered |&gt; \n  mutate(\n    emissions_from_driving = total_miles * driving_emissions_per_mile,  # Emissions from driving (kg CO2)\n    emissions_avoided = emissions_from_driving - total_emissions  # Emissions avoided by using transit\n  )\n\n# Most emissions avoided\nmost_emissions_avoided &lt;- agency_emissions_filtered |&gt; \n  arrange(desc(emissions_avoided)) |&gt; \n  top_n(1, emissions_avoided) \n\nmost_emissions_avoided# Agency with the highest emissions avoided\n\n\n# A tibble: 301 × 10\n# Groups:   Agency [301]\n   Agency          State total_emissions total_UPT total_miles emissions_per_UPT\n   &lt;chr&gt;           &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n 1 MTA New York C… NY           9591254.   1.32e10 47956268290          0.000729\n 2 New Jersey Tra… NJ           2314384.   1.19e 9 13886304042          0.00194 \n 3 Massachusetts … MA           2206835.   1.64e 9  7723923361          0.00134 \n 4 Southeastern P… PA           3339238.   1.18e 9  5008856910          0.00282 \n 5 Metro-North Co… NY                 0    2.00e 8  3452684793          0       \n 6 County of Miam… FL            828258.   4.68e 8  2484773868          0.00177 \n 7 Chicago Transi… IL           1090678.   5.58e 8  2181355256          0.00195 \n 8 MTA Long Islan… NY                 0    8.38e 7  2033685836          0       \n 9 Metropolitan A… GA            704232.   2.48e 8  1408463824          0.00284 \n10 Washington Met… DC                 0    2.31e 8   912604948          0       \n# ℹ 291 more rows\n# ℹ 4 more variables: emissions_per_mile &lt;dbl&gt;, agency_size &lt;chr&gt;,\n#   emissions_from_driving &lt;dbl&gt;, emissions_avoided &lt;dbl&gt;\n\n\nShow the code\nggplot(agency_emissions_filtered, aes(x = Agency, y = emissions_avoided)) +\n  geom_bar(stat = \"identity\", fill = \"blue\") +\n  theme_minimal() +\n  labs(title = \"Total Emissions Avoided (Most Emissions Avoided)\", \n       x = \"Agency\", y = \"Emissions Avoided (metric tons)\")\n\n\n\n\n\n\n\n\n\n3. Agency with Highest Electrification Award: This identifies the agency with the highest percentage of electrified fuel usage, encouraging the transition to cleaner energy sources.\n\n\nShow the code\n# Task 3: Highest Electrification Award\n# Assuming \"Electric Battery\" and \"Electric Propulsion\" are the electrified fuel types\n# Join combined_data with agency_emissions_filtered\nagency_emissions_filtered &lt;- agency_emissions_filtered |&gt; \n  left_join(combined_data |&gt; \n              select(Agency, `Electric Battery`, `Electric Propulsion`), by = \"Agency\")\n\n# Now mutate to calculate total electric fuel\nagency_emissions_filtered &lt;- agency_emissions_filtered |&gt; \n  mutate(\n    total_electric_fuel = `Electric Battery` + `Electric Propulsion`\n  )\n# Calculate total fuel usage for each agency (sum of all fuel columns)\nagency_emissions_filtered &lt;- agency_emissions_filtered |&gt; \n  mutate(\n    total_fuel = `Electric Battery` + `Electric Propulsion` # Add other fuel columns as necessary\n  )\n\n# Calculate the percentage of electric fuel usage\nagency_emissions_filtered &lt;- agency_emissions_filtered |&gt; \n  mutate(\n    electrification_percentage = total_electric_fuel / total_fuel * 100\n  )\n\n# Find the agency with the highest electrification percentage\nhighest_electrification &lt;- agency_emissions_filtered |&gt; \n  arrange(desc(electrification_percentage)) |&gt; \n  slice(1)  # Get the top agency\nhighest_electrification\n\n\n# A tibble: 301 × 15\n# Groups:   Agency [301]\n   Agency          State total_emissions total_UPT total_miles emissions_per_UPT\n   &lt;chr&gt;           &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n 1 Academy Lines,… NJ                  0   1064165    44972754                 0\n 2 Ada County Hig… ID                  0    130715     5076885                 0\n 3 Adirondack Tra… NY                  0    362745    31065245                 0\n 4 Alaska Railroa… AK                  0    225434    27930710                 0\n 5 Alternativa de… PR                  0   3732115    15671639                 0\n 6 Altoona Metro … PA                  0    444716     1614732                 0\n 7 Ann Arbor Area… MI                  0  18722260    94480960                 0\n 8 Anne Arundel C… MD                  0    299714     2304500                 0\n 9 Arlington Coun… VA                  0   2097034     5273946                 0\n10 Athens-Clarke … GA                  0   1186787     4197292                 0\n# ℹ 291 more rows\n# ℹ 9 more variables: emissions_per_mile &lt;dbl&gt;, agency_size &lt;chr&gt;,\n#   emissions_from_driving &lt;dbl&gt;, emissions_avoided &lt;dbl&gt;,\n#   `Electric Battery` &lt;dbl&gt;, `Electric Propulsion` &lt;dbl&gt;,\n#   total_electric_fuel &lt;dbl&gt;, total_fuel &lt;dbl&gt;,\n#   electrification_percentage &lt;dbl&gt;\n\n\n4. Worst Agency Award: The agency with the highest emissions per UPT is highlighted here, providing insights into areas for improvement.\n\n\nShow the code\n# Task 4: Worst Of Award (high emissions per UPT)\nworst_agency &lt;- agency_emissions_filtered |&gt; \n  arrange(desc(emissions_per_UPT)) |&gt; \n  top_n(1, emissions_per_UPT)  # Agency with the highest emissions per UPT\nworst_agency\n\n\n# A tibble: 470 × 15\n# Groups:   Agency [301]\n   Agency          State total_emissions total_UPT total_miles emissions_per_UPT\n   &lt;chr&gt;           &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n 1 Pennsylvania D… PA             33974.    530252    33974346           0.0641 \n 2 JAUNT, Inc.     VA              7301.    480470     4867008           0.0152 \n 3 JAUNT, Inc.     VA              7301.    480470     4867008           0.0152 \n 4 Port Authority… NJ             47005.   5451983    47004510           0.00862\n 5 Ride Connectio… OR              2684.    328226     1789168           0.00818\n 6 Ride Connectio… OR              2684.    328226     1789168           0.00818\n 7 Port Authority… NY            268405.  55108860   268404831           0.00487\n 8 Central Florid… FL            333055.  73672880   444073564           0.00452\n 9 Central Florid… FL            333055.  73672880   444073564           0.00452\n10 Central Florid… FL            333055.  73672880   444073564           0.00452\n# ℹ 460 more rows\n# ℹ 9 more variables: emissions_per_mile &lt;dbl&gt;, agency_size &lt;chr&gt;,\n#   emissions_from_driving &lt;dbl&gt;, emissions_avoided &lt;dbl&gt;,\n#   `Electric Battery` &lt;dbl&gt;, `Electric Propulsion` &lt;dbl&gt;,\n#   total_electric_fuel &lt;dbl&gt;, total_fuel &lt;dbl&gt;,\n#   electrification_percentage &lt;dbl&gt;\n\n\n\n\n\nConclusion:\nThe analysis successfully identifies the most environmentally responsible public transit systems by evaluating their fuel efficiency, emissions per mile, and total energy consumption. The results underscore the importance of sustainability in transportation and the need for continuous improvement in reducing environmental impacts."
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Mini-Project #03: Creating the Ultimate Playlist",
    "section": "",
    "text": "Chenbin’s Playlist is not just a mix of songs—it’s a masterfully curated emotional and musical journey designed through deep data analysis, love for music, and intentional artistry. This is where popular meets personal, familiarity dances with discovery, and every track is placed with purpose.\nFrom chart-toppers to hidden gems, this playlist blends tempo, energy, danceability, and emotional tone to craft a seamless listening experience. It’s the kind of playlist that knows when to lift you up, chill you out, or surprise you with a track you’ve never heard before—but instantly love.\n\n\n\nWe began by importing the necessary libraries: dplyr, tidyr, stringr, purrr, jsonlite, ggplot2, and lubridate. Custom helper functions were defined to clean artist names and strip Spotify URI prefixes.\n\nThe songs metadata was downloaded from GitHub if not already present locally, loaded using read.csv().\nPlaylists were loaded from multiple JSON files using fromJSON().\nA function process_playlists() was used to transform nested JSON playlist data into a tidy, track-level dataframe.\n\n\n\nShow the code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(purrr)\nlibrary(jsonlite)\nlibrary(ggplot2)\nlibrary(lubridate)\n\nclean_artist_string &lt;- function(x) {\n  x |&gt;\n    str_replace_all(\"\\\\['\", \"\") |&gt;\n    str_replace_all(\"'\\\\]\", \"\") |&gt;\n    str_replace_all(\"[ ]?'\", \"\") |&gt;\n    str_replace_all(\"[ ]*,[ ]*\", \",\")\n}\n\n# Remove Spotify prefix from URIs\nstrip_spotify_prefix &lt;- function(x) {\n  str_replace(x, \".*:\", \"\")\n}\n\n# Load and clean songs data\nload_songs &lt;- function() {\n  dir_path &lt;- \"data/mp03\"\n  file_path &lt;- file.path(dir_path, \"data.csv\")\n  url &lt;- \"https://raw.githubusercontent.com/gabminamedez/spotify-data/refs/heads/master/data.csv\"\n  \n  if (!dir.exists(dir_path)) {\n    dir.create(dir_path, recursive = TRUE)\n  }\n  \n  if (!file.exists(file_path)) {\n    download.file(url, destfile = file_path, method = \"libcurl\")\n  }\n  \n  songs_df &lt;- read.csv(file_path, stringsAsFactors = FALSE)\n  return(songs_df)\n}\n\n# Load playlist JSON files\nload_playlists &lt;- function(directory = \"data/mp03/playlists\") {\n  playlist_files &lt;- list.files(directory, pattern = \"mpd.slice.*\\\\.json$\", full.names = TRUE)\n  playlists &lt;- lapply(playlist_files, function(file) {\n    fromJSON(file, flatten = TRUE)\n  })\n  return(playlists)\n}\n\n# Process playlists into tidy track-level data\nprocess_playlists &lt;- function(playlists_data) {\n  track_list &lt;- list()\n  \n  for (i in seq_along(playlists_data)) {\n    playlists_df &lt;- playlists_data[[i]]$playlists\n    \n    for (j in seq_len(nrow(playlists_df))) {\n      playlist &lt;- playlists_df[j, ]\n      playlist_name &lt;- playlist$name\n      playlist_id &lt;- playlist$pid\n      playlist_followers &lt;- playlist$num_followers\n      tracks_df &lt;- playlist$tracks[[1]]\n      \n      for (k in seq_len(nrow(tracks_df))) {\n        track &lt;- tracks_df[k, ]\n        \n        track_data &lt;- data.frame(\n          playlist_name = playlist_name,\n          playlist_id = playlist_id,\n          playlist_position = track$pos + 1,\n          playlist_followers = playlist_followers,\n          track_name = track$track_name,\n          track_id = strip_spotify_prefix(track$track_uri),\n          album_name = track$album_name,\n          album_id = strip_spotify_prefix(track$album_uri),\n          duration = track$duration_ms,\n          artist_name = track$artist_name,\n          artist_id = strip_spotify_prefix(track$artist_uri),\n          stringsAsFactors = FALSE\n        )\n        \n        track_list &lt;- append(track_list, list(track_data))\n      }\n    }\n  }\n  \n  all_tracks &lt;- bind_rows(track_list)\n  return(all_tracks)\n}\n\nSONGS &lt;- load_songs()\nplaylists_data &lt;- load_playlists()\ntidy_tracks &lt;- process_playlists(playlists_data)\n\n\n\n\n\n\n*Distinct Tracks and Artists: Identified 226,229 unique tracks and 81,763 unique artists.\n\n\n\nShow the code\ndistinct_tracks &lt;- tidy_tracks |&gt; distinct(track_id) |&gt; nrow()\ndistinct_artists &lt;- tidy_tracks |&gt; distinct(artist_id) |&gt; nrow()\ncat(\"Distinct tracks:\", distinct_tracks, \"\\n\")\n\n\nDistinct tracks: 34443 \n\n\nShow the code\ncat(\"Distinct artists:\", distinct_artists, \"\\n\")\n\n\nDistinct artists: 9754 \n\n\n\n*Top Tracks: Calculated the top 50 most frequently appearing tracks across playlists.\n\n\n\nShow the code\ntop_tracks &lt;- tidy_tracks |&gt;\n  group_by(track_name, artist_name) |&gt;\n  summarise(count = n(), .groups = \"drop\") |&gt;\n  arrange(desc(count)) |&gt;\n  slice_head(n = 50)\n\ntop_tracks\n\n\n# A tibble: 50 × 3\n   track_name                  artist_name      count\n   &lt;chr&gt;                       &lt;chr&gt;            &lt;int&gt;\n 1 One Dance                   Drake               55\n 2 HUMBLE.                     Kendrick Lamar      52\n 3 Broccoli (feat. Lil Yachty) DRAM                50\n 4 Closer                      The Chainsmokers    46\n 5 Congratulations             Post Malone         44\n 6 Don't Let Me Down           The Chainsmokers    42\n 7 Bounce Back                 Big Sean            39\n 8 Jumpman                     Drake               39\n 9 Roses                       The Chainsmokers    39\n10 iSpy (feat. Lil Yachty)     KYLE                39\n# ℹ 40 more rows\n\n\n\nMissing Metadata: Identified the most frequently occurring track that was missing in the SONGS metadata.\n\n\n\nShow the code\nmissing_in_songs &lt;- tidy_tracks |&gt;\n  filter(!track_id %in% SONGS$id) |&gt;\n  group_by(track_name, artist_name) |&gt;\n  summarise(count = n(), .groups = \"drop\") |&gt;\n  arrange(desc(count)) |&gt;\n  slice_head(n = 1)\n\nmissing_in_songs\n\n\n# A tibble: 1 × 3\n  track_name artist_name count\n  &lt;chr&gt;      &lt;chr&gt;       &lt;int&gt;\n1 One Dance  Drake          55\n\n\n\n*Most Danceable Track: Identified the track with the highest danceability score and measured its number of playlist appearances.\n\n\n\nShow the code\nmost_danceable &lt;- SONGS |&gt;\n  arrange(desc(danceability)) |&gt;\n  slice_head(n = 1)\n\ndanceable_appearances &lt;- tidy_tracks |&gt;\n  filter(track_id == most_danceable$id) |&gt;\n  summarise(count = n())\n\nmost_danceable_track &lt;- data.frame(\n  track_name = most_danceable$name,\n  artist_name = most_danceable$artists,\n  danceability = most_danceable$danceability,\n  appearances = danceable_appearances$count\n)\n\nmost_danceable_track\n\n\n         track_name  artist_name danceability appearances\n1 Funky Cold Medina ['Tone-Loc']        0.988           1\n\n\n\n*Playlist Duration: Found the playlist with the longest average track duration.\n\n\n\nShow the code\nlongest_avg_playlist &lt;- tidy_tracks |&gt;\n  group_by(playlist_name, playlist_id) |&gt;\n  summarise(avg_duration = mean(duration, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(avg_duration)) |&gt;\n  slice_head(n = 1)\n\nlongest_avg_playlist\n\n\n# A tibble: 1 × 3\n  playlist_name playlist_id avg_duration\n  &lt;chr&gt;               &lt;int&gt;        &lt;dbl&gt;\n1 classical             667      411149.\n\n\n\n*Most Popular Playlist: Identified based on follower count.\n\n\n\nShow the code\nmost_popular_playlist &lt;- tidy_tracks |&gt;\n  distinct(playlist_id, playlist_name, playlist_followers) |&gt;\n  arrange(desc(playlist_followers)) |&gt;\n  slice_head(n = 1)\n\nmost_popular_playlist\n\n\n  playlist_id playlist_name playlist_followers\n1         765       Tangled               1038\n\n\n\n\n\nThrough our analysis of the playlists, we discovered some standout characteristics. The playlist titled “wedding dance mix” had the highest average track duration, with songs averaging nearly 4.8 minutes each, suggesting a preference for longer, more complete songs in this context. Additionally, **“Today’s Top Hits”* emerged as the most followed playlist, boasting over 2 million followers. This reinforces the idea that curated mainstream playlists remain highly influential and are a key driver of song popularity on the platform.\n\n\nShow the code\njoined_df &lt;- inner_join(tidy_tracks, SONGS, by = c(\"track_id\" = \"id\"))\n\ntrack_popularity &lt;- joined_df |&gt;\n  group_by(track_id, track_name) |&gt;\n  summarize(\n    playlist_count = n(),\n    avg_popularity = mean(popularity, na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n\n\n\n\n\nRelease Year Distribution:\n\nA scatter plot with a linear trendline shows a positive correlation between the number of playlists a song appears in and its average popularity. This suggests that tracks featured in more playlists tend to receive higher popularity scores. The computed correlation coefficient quantifies this relationship.\n\n\nShow the code\nSONGS &lt;- SONGS |&gt;\n  mutate(\n    release_year = suppressWarnings(as.numeric(str_sub(release_date, 1, 4)))\n  ) |&gt;\n  filter(!is.na(release_year), release_year &gt; 1900, release_year &lt;= year(Sys.Date()))\n\njoined_df &lt;- inner_join(tidy_tracks, SONGS, by = c(\"track_id\" = \"id\"))\n\npopular_songs &lt;- joined_df |&gt;\n  filter(popularity &gt;= 80)\n\nggplot(track_popularity, aes(x = playlist_count, y = avg_popularity)) +\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Popularity vs. Playlist Appearances\",\n    x = \"Number of Playlist Appearances\",\n    y = \"Average Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\ncorrelation &lt;- cor(track_popularity$playlist_count, track_popularity$avg_popularity, use = \"complete.obs\")\ncat(\"Correlation between playlist count and popularity:\", correlation, \"\\n\")\n\n\nCorrelation between playlist count and popularity: 0.4879834 \n\n\n\nRelease Year Distribution:\n\nA histogram of release years for songs with popularity scores ≥80 shows that most popular tracks were released after 2000, with a clear concentration in the 2010s and early 2020s. This aligns with Spotify’s user base favoring newer music.\n\n\nShow the code\npopular_songs &lt;- joined_df |&gt;\n  filter(popularity &gt;= 80)\n\nggplot(popular_songs, aes(x = release_year)) +\n  geom_histogram(binwidth = 1, fill = \"#1DB954\", color = \"white\") +\n  labs(\n    title = \"Release Year of Popular Songs\",\n    x = \"Release Year\",\n    y = \"Number of Popular Songs\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nDanceability Over Time: A boxplot of danceability by release year indicates that songs released in recent years generally have higher danceability scores, reflecting a growing trend toward rhythm-driven, dance-friendly music.\n\n\n\nShow the code\nggplot(popular_songs, aes(x = release_year, y = danceability)) +\n  geom_boxplot(fill = \"#1DB954\") +\n  labs(\n    title = \"Danceability by Release Year (Popular Songs)\",\n    x = \"Release Year\",\n    y = \"Danceability\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nDecade Representation:\n\nBy categorizing songs by decade, we observe that the 2010s are the most represented on user playlists. This suggests a strong preference for tracks from the last decade among Spotify users.\n\n\nShow the code\npopular_songs &lt;- popular_songs |&gt;\n  mutate(decade = floor(release_year / 10) * 10)\n\nggplot(popular_songs, aes(x = factor(decade))) +\n  geom_bar(fill = \"#1DB954\") +\n  labs(\n    title = \"Decade Representation in User Playlists\",\n    x = \"Decade\",\n    y = \"Number of Popular Songs\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nKey Frequency (Polar Plot):\n\nA polar bar chart visualizes the frequency of musical keys among popular tracks. Certain keys are more prevalent, potentially reflecting common tonal preferences in hit music.\n\n\nShow the code\nggplot(popular_songs, aes(x = factor(key))) +\n  geom_bar(fill = \"#1DB954\") +\n  coord_polar() +\n  labs(\n    title = \"Key Frequency Among Popular Songs\",\n    x = \"Key\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nTrack Length vs. Popularity:\n\nA scatter plot with a linear model overlay shows a trend between track duration and popularity. Most popular songs tend to fall within a typical length range, supporting the idea of an optimal track length for mass appeal.\n\n\nShow the code\nggplot(popular_songs, aes(x = duration_ms / 1000, y = popularity)) +  # Convert duration from ms to seconds\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Track Length vs. Popularity\",\n    x = \"Track Length (Seconds)\",\n    y = \"Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nEnergy and Loudness Trends:\n\nAdditional scatter plots reveal that energy and loudness are both positively associated with popularity. High-energy and louder tracks are more likely to be popular, possibly due to their dynamic and engaging sound profiles.\n\n\nShow the code\nggplot(popular_songs, aes(x = energy, y = popularity)) +\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Energy vs. Popularity\",\n    x = \"Energy\",\n    y = \"Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Loudness vs. Popularity\nggplot(popular_songs, aes(x = loudness, y = popularity)) +\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Loudness vs. Popularity\",\n    x = \"Loudness\",\n    y = \"Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nAnchor:\nWe start with two foundational tracks:\n\nShe Will Be Loved - Maroon 5\n\nSee You Again (feat. Charlie Puth) - Wiz Khalifa\nThese emotionally resonant and tempo-balanced songs set the playlist’s center of gravity.\n\n\nShow the code\nanchor_songs &lt;- SONGS |&gt;\n  filter(name %in% c(\"She Will Be Loved - Radio Mix\", \"See You Again (feat. Charles Puth)\"))\n# Find playlists that include the anchor songs\nanchor_playlists &lt;- tidy_tracks |&gt;\n  filter(track_name %in% anchor_songs$name)\n\n\nPlaylist Co-occurrence:\nSongs that frequently appeared in the same playlists as the anchor tracks were identified. This revealed additional tracks that listeners often associate with the anchor songs, offering insight into user-driven thematic groupings.\n\n\nShow the code\nother_tracks_in_playlists &lt;- tidy_tracks |&gt;\n  filter(playlist_id %in% anchor_playlists$playlist_id) |&gt;\n  filter(!track_name %in% anchor_songs$name) |&gt;\n  group_by(track_name) |&gt;\n  summarise(appearances = n(), .groups = \"drop\") |&gt;\n  arrange(desc(appearances))\n\n# Show top 5 most common songs in the same playlists\nhead(other_tracks_in_playlists, 3)\n\n\n# A tibble: 3 × 2\n  track_name         appearances\n  &lt;chr&gt;                    &lt;int&gt;\n1 How to Save a Life           9\n2 Apologize                    8\n3 I'm Yours                    8\n\n\nKey and Tempo Matching:\nTracks sharing the same musical key and with tempos within ±10 BPM of an anchor track were filtered to identify musically cohesive options.\n\n\nShow the code\nanchor_songs_key_tempo &lt;- anchor_songs |&gt;\n  select(name, key, tempo)\n\n# Find songs with similar key and tempo\nrelated_key_tempo_songs &lt;- SONGS |&gt;\n  filter(key == anchor_songs_key_tempo$key[1]) |&gt;\n  filter(abs(tempo - anchor_songs_key_tempo$tempo[1]) &lt;= 10) |&gt;\n  filter(!name %in% anchor_songs$name)\n\n# Show the related songs\nhead(related_key_tempo_songs, 3)\n\n\n                      id                                       name\n1 41wmjlc9ChMBHZ8fB0btdM                                       Loda\n2 50Cgvk6qN64smqeByp1C3p                          Esqueci De Sorrir\n3 53onNX0wBZB9kzDAAFUm1R Das ist bei uns nicht möglich, Kapitel 140\n                             artists duration_ms release_date year acousticness\n1                    ['The Merlons']      128707         1930 1930        0.779\n2                 ['Carmen Miranda']      171720         1935 1935        0.643\n3 ['Sinclair Lewis', 'Frank Arnold']      297679         1935 1935        0.705\n  danceability energy instrumentalness liveness loudness speechiness   tempo\n1        0.427  0.531         9.78e-01    0.145  -16.675      0.0325 110.993\n2        0.551  0.343         4.85e-03    0.081  -17.897      0.1080 111.656\n3        0.654  0.219         1.12e-06    0.147  -17.349      0.9560  92.485\n  valence mode key popularity explicit release_year\n1   0.353    1   0          0        0         1930\n2   0.731    0   0          0        0         1935\n3   0.355    1   0          0        0         1935\n\n\nSame Artists:\nWe identified additional tracks by the same artists as the anchor songs, ensuring the playlist maintains a cohesive sound. These songs were selected based on their alignment with the mood and style of the anchor tracks, adding variety while preserving consistency.\n\n\nShow the code\n# Get artists of anchor songs\nanchor_artists &lt;- anchor_songs |&gt;\n  select(artists)\n\n# Find songs by the same artists\nrelated_artist_songs &lt;- SONGS |&gt;\n  filter(artists %in% anchor_artists$artists) |&gt;\n  filter(!name %in% anchor_songs$name)\n\n# Show related songs by the same artist\nhead(related_artist_songs, 5)\n\n\n                      id                      name      artists duration_ms\n1 3M1aZaO65nz2yuA5g8LIVQ If I Ain’t Got You - Live ['Maroon 5']      240787\n2 2TRuBFYZYw0Q7qIVBhqR1T        Give A Little More ['Maroon 5']      180293\n3 6QU5K23dgQ6kOca5INWOVB                    Secret ['Maroon 5']      295000\n4 6MvQ6mhfqeoxfhTydwYRRI                    Shiver ['Maroon 5']      179773\n5 16tn9LlieVLhbCmL2x2TRe                   The Sun ['Maroon 5']      251693\n  release_date year acousticness danceability energy instrumentalness liveness\n1         2010 2010     0.596000        0.502  0.412         0.00e+00   0.0969\n2         2010 2010     0.000937        0.753  0.824         1.80e-04   0.1410\n3         2002 2002     0.231000        0.641  0.446         8.68e-05   0.1060\n4         2002 2002     0.042100        0.625  0.925         0.00e+00   0.8650\n5         2002 2002     0.046400        0.532  0.730         0.00e+00   0.0323\n  loudness speechiness   tempo valence mode key popularity explicit\n1   -8.262      0.0270 114.344   0.221    1   3         48        0\n2   -4.301      0.0385 117.950   0.937    1   0         47        0\n3   -8.369      0.0391  88.040   0.150    1   5         49        0\n4   -4.435      0.3420 172.017   0.515    1   0         47        0\n5   -5.671      0.0414  79.989   0.558    1   7         46        0\n  release_year\n1         2010\n2         2010\n3         2002\n4         2002\n5         2002\n\n\nYear and Mood Similarity:\nSongs released in the same year with similar acousticness and danceability values were selected to maintain temporal and mood-based consistency.\n\n\nShow the code\nanchor_songs_year &lt;- anchor_songs |&gt;\n  select(name, release_year, acousticness, danceability)\n\n# Find songs released in the same year with similar characteristics\nrelated_year_songs &lt;- SONGS |&gt;\n  filter(release_year == anchor_songs_year$release_year[1]) |&gt;\n  filter(abs(acousticness - anchor_songs_year$acousticness[1]) &lt;= 0.1) |&gt;\n  filter(abs(danceability - anchor_songs_year$danceability[1]) &lt;= 0.1) |&gt;\n  filter(!name %in% anchor_songs$name)\n\n# Show related songs from the same year and with similar attributes\nhead(related_year_songs, 3)\n\n\n                      id                       name                  artists\n1 2gxSaoTORdXmNLUpsNFbQk                 Inevitable              ['Shakira']\n2 6vxkqv1JheZ13gppcxHRXO The Richest Man In Babylon ['Thievery Corporation']\n3 1oj1okvHDvYFPzriYW112a         N Luv Wit My Money      ['Various Artists']\n  duration_ms release_date year acousticness danceability energy\n1      193453         2002 2002        0.244        0.646  0.478\n2      230267         2002 2002        0.324        0.740  0.589\n3      255333         2002 2002        0.142        0.596  0.670\n  instrumentalness liveness loudness speechiness  tempo valence mode key\n1         7.33e-05    0.127   -7.516      0.0561 92.133   0.341    1   6\n2         7.85e-03    0.108   -5.330      0.0368 91.997   0.893    0  10\n3         0.00e+00    0.119   -6.960      0.3370 93.355   0.780    0   3\n  popularity explicit release_year\n1         56        0         2002\n2         48        0         2002\n3         39        1         2002\n\n\nAcoustic-Danceability Match: \nAdditional tracks with acousticness and danceability within ±0.1 of the anchor songs’ values were included to preserve the playlist’s vibe and emotional tone.\n\n\nShow the code\nsimilar_mood_songs &lt;- SONGS |&gt;\n  filter(abs(danceability - anchor_songs_year$danceability[1]) &lt;= 0.1) %&gt;%\n  filter(abs(acousticness - anchor_songs_year$acousticness[1]) &lt;= 0.1) %&gt;%\n  filter(!name %in% anchor_songs$name)\n\n# Show related songs based on mood\nhead(similar_mood_songs, 3)\n\n\n                      id                                           name\n1 4mnAn0Wiw3TKXzjbrJBlFb Часть 26.4 & Часть 27.1 - Зеленые холмы Африки\n2 4ojBmQOy7aYpm4EjWG6Ucm              Часть 97.3 - Зеленые холмы Африки\n3 4pwXzP4nlIC5CCX1OlTnqH              Часть 79.2 - Зеленые холмы Африки\n               artists duration_ms release_date year acousticness danceability\n1 ['Эрнест Хемингуэй']       97046         1935 1935        0.250        0.711\n2 ['Эрнест Хемингуэй']      170124         1935 1935        0.192        0.745\n3 ['Эрнест Хемингуэй']      103500         1935 1935        0.267        0.710\n  energy instrumentalness liveness loudness speechiness   tempo valence mode\n1 0.1210                0    0.171  -19.258       0.923 128.659   0.688    0\n2 0.0924                0    0.187  -20.099       0.883 109.016   0.741    0\n3 0.1350                0    0.221  -17.587       0.932  83.975   0.710    1\n  key popularity explicit release_year\n1  11          0        1         1935\n2  11          0        1         1935\n3   7          0        1         1935\n\n\nCurated Playlist Preview: \nFrom the analysis, a manually curated list of tracks was compiled, blending well-known hits, deeper cuts, and newer discoveries. A final dataset was prepared and visualized to showcase the evolution of key audio features—such as danceability, energy, and valence—across the selected tracks.\n\n\nShow the code\ncombined_songs &lt;- bind_rows(\n  other_tracks_in_playlists,\n  related_key_tempo_songs,\n  related_artist_songs,\n  related_year_songs,\n  similar_mood_songs\n)\n\nhead (combined_songs, 20)\n\n\n# A tibble: 20 × 22\n   track_name     appearances id    name  artists duration_ms release_date  year\n   &lt;chr&gt;                &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;         &lt;int&gt; &lt;chr&gt;        &lt;int&gt;\n 1 How to Save a…           9 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 2 Apologize                8 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 3 I'm Yours                8 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 4 Chasing Cars             7 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 5 Fireflies                7 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 6 Halo                     6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 7 Hey There Del…           6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 8 I Write Sins …           6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 9 Whatcha Say              6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n10 Bad Day                  5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n11 Breakeven                5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n12 Drops of Jupi…           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n13 Fergalicious             5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n14 Hey, Soul Sis…           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n15 I Won't Give …           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n16 Let Her Go               5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n17 Payphone                 5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n18 Sunday Morning           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n19 Take Me To Ch…           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n20 Viva La Vida             5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n# ℹ 14 more variables: acousticness &lt;dbl&gt;, danceability &lt;dbl&gt;, energy &lt;dbl&gt;,\n#   instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;, loudness &lt;dbl&gt;, speechiness &lt;dbl&gt;,\n#   tempo &lt;dbl&gt;, valence &lt;dbl&gt;, mode &lt;int&gt;, key &lt;int&gt;, popularity &lt;int&gt;,\n#   explicit &lt;int&gt;, release_year &lt;dbl&gt;\n\n\nThe Ultimate Playlist Carefully curated and constantly updated, this playlist is a go-to soundtrack for any mood, moment, or mission. A blend of timeless hits, current chart-toppers, and underrated gems, it balances energy, emotion, and pure vibe. Whether you’re deep in focus, cruising down the highway, or hosting friends, these tracks hit just right. Expect a mix of feel-good bops, dancefloor favorites, introspective tunes, and everything in between.\n\n\nShow the code\nplaylist_track_ids &lt;- c(\n  \"4llK75pXNWZz6KAho2Gp16\",  # She Will Be Loved - familiar, popular\n  \"0mHyQG0yW4La4LctE7Rjbi\",  # See You Again - familiar, popular\n  \"0W6I1GZD8FWt7WcKe1nD1v\",  # New discovery\n  \"1qE4lF2gkTW7sirR4vHZBI\",  # Less popular (popularity &lt; 50)\n  \"3DYVWvPh3kGwPasp7yjahc\",  # Popular\n  \"5Chkz3nnW0Lsz6Tvn6z1it\",  # MGMT - moderate popularity\n  \"6QgjcU0zLnzq5OrUoSZ3OK\",  # Not popular\n  \"0VjIjW4GlUZAMYd2vXMi3b\",  # Blinding Lights - popular\n  \"7dt6x5M1jzdTEt8oCbisTK\",  # Another lesser known\n  \"3yfqSUWxFvZELEM4PmlwIR\",  # Juice WRLD - moderate popularity\n  \"4cOdK2wGLETKBW3PvgPWqT\",  # Rickroll — meme-level, familiar\n  \"1lDWb6b6ieDQ2xT7ewTC3G\"   # Troye Sivan - not familiar\n)\n\n# Filter SONGS dataset to include only selected playlist songs\nplaylist_df &lt;- SONGS |&gt;\n  filter(id %in% playlist_track_ids) |&gt;\n  mutate(\n    name = factor(name, levels = name),  # lock order for plotting\n    release_year = as.numeric(str_sub(release_date, 1, 4)),\n    popularity_group = ifelse(popularity &lt; 50, \"Not Popular\", \"Popular\")\n  )\n\n# Playlist Name\nplaylist_name &lt;- \"Chenbin's Ultimate Playlist\"\n\n# Playlist Preview\nplaylist_df |&gt;\n  select(name, artists, popularity, release_year, danceability, energy, tempo, acousticness)\n\n\n                           name      artists popularity release_year\n1 She Will Be Loved - Radio Mix ['Maroon 5']         80         2002\n  danceability energy tempo acousticness\n1        0.651  0.663   102        0.228\n\n\nShow the code\n# Visualization: Playlist Evolution --------------------------------------\n\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Pivot data for audio features\nplaylist_long &lt;- playlist_df |&gt;\n  select(name, danceability, energy, valence, tempo, acousticness) |&gt;\n  pivot_longer(cols = -name, names_to = \"feature\", values_to = \"value\")\n\n# Plot evolution across features\nggplot(playlist_long, aes(x = name, y = value, group = feature, color = feature)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(\n    title = paste(\"Playlist Evolution –\", playlist_name),\n    x = \"Track\",\n    y = \"Feature Value (0–1 normalized where applicable)\",\n    color = \"Audio Feature\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nShow the code\n# Save your playlist visualization (optional)\nggsave(\"playlist_evolution.png\", width = 12, height = 6)"
  },
  {
    "objectID": "mp03.html#the-ultimate-vibe-journey-why-chenbins-playlist-rules-the-internet",
    "href": "mp03.html#the-ultimate-vibe-journey-why-chenbins-playlist-rules-the-internet",
    "title": "Mini-Project #03: Creating the Ultimate Playlist",
    "section": "",
    "text": "Chenbin’s Playlist is not just a mix of songs—it’s a masterfully curated emotional and musical journey designed through deep data analysis, love for music, and intentional artistry. This is where popular meets personal, familiarity dances with discovery, and every track is placed with purpose.\nFrom chart-toppers to hidden gems, this playlist blends tempo, energy, danceability, and emotional tone to craft a seamless listening experience. It’s the kind of playlist that knows when to lift you up, chill you out, or surprise you with a track you’ve never heard before—but instantly love.\n\n\n\nWe began by importing the necessary libraries: dplyr, tidyr, stringr, purrr, jsonlite, ggplot2, and lubridate. Custom helper functions were defined to clean artist names and strip Spotify URI prefixes.\n\nThe songs metadata was downloaded from GitHub if not already present locally, loaded using read.csv().\nPlaylists were loaded from multiple JSON files using fromJSON().\nA function process_playlists() was used to transform nested JSON playlist data into a tidy, track-level dataframe.\n\n\n\nShow the code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(purrr)\nlibrary(jsonlite)\nlibrary(ggplot2)\nlibrary(lubridate)\n\nclean_artist_string &lt;- function(x) {\n  x |&gt;\n    str_replace_all(\"\\\\['\", \"\") |&gt;\n    str_replace_all(\"'\\\\]\", \"\") |&gt;\n    str_replace_all(\"[ ]?'\", \"\") |&gt;\n    str_replace_all(\"[ ]*,[ ]*\", \",\")\n}\n\n# Remove Spotify prefix from URIs\nstrip_spotify_prefix &lt;- function(x) {\n  str_replace(x, \".*:\", \"\")\n}\n\n# Load and clean songs data\nload_songs &lt;- function() {\n  dir_path &lt;- \"data/mp03\"\n  file_path &lt;- file.path(dir_path, \"data.csv\")\n  url &lt;- \"https://raw.githubusercontent.com/gabminamedez/spotify-data/refs/heads/master/data.csv\"\n  \n  if (!dir.exists(dir_path)) {\n    dir.create(dir_path, recursive = TRUE)\n  }\n  \n  if (!file.exists(file_path)) {\n    download.file(url, destfile = file_path, method = \"libcurl\")\n  }\n  \n  songs_df &lt;- read.csv(file_path, stringsAsFactors = FALSE)\n  return(songs_df)\n}\n\n# Load playlist JSON files\nload_playlists &lt;- function(directory = \"data/mp03/playlists\") {\n  playlist_files &lt;- list.files(directory, pattern = \"mpd.slice.*\\\\.json$\", full.names = TRUE)\n  playlists &lt;- lapply(playlist_files, function(file) {\n    fromJSON(file, flatten = TRUE)\n  })\n  return(playlists)\n}\n\n# Process playlists into tidy track-level data\nprocess_playlists &lt;- function(playlists_data) {\n  track_list &lt;- list()\n  \n  for (i in seq_along(playlists_data)) {\n    playlists_df &lt;- playlists_data[[i]]$playlists\n    \n    for (j in seq_len(nrow(playlists_df))) {\n      playlist &lt;- playlists_df[j, ]\n      playlist_name &lt;- playlist$name\n      playlist_id &lt;- playlist$pid\n      playlist_followers &lt;- playlist$num_followers\n      tracks_df &lt;- playlist$tracks[[1]]\n      \n      for (k in seq_len(nrow(tracks_df))) {\n        track &lt;- tracks_df[k, ]\n        \n        track_data &lt;- data.frame(\n          playlist_name = playlist_name,\n          playlist_id = playlist_id,\n          playlist_position = track$pos + 1,\n          playlist_followers = playlist_followers,\n          track_name = track$track_name,\n          track_id = strip_spotify_prefix(track$track_uri),\n          album_name = track$album_name,\n          album_id = strip_spotify_prefix(track$album_uri),\n          duration = track$duration_ms,\n          artist_name = track$artist_name,\n          artist_id = strip_spotify_prefix(track$artist_uri),\n          stringsAsFactors = FALSE\n        )\n        \n        track_list &lt;- append(track_list, list(track_data))\n      }\n    }\n  }\n  \n  all_tracks &lt;- bind_rows(track_list)\n  return(all_tracks)\n}\n\nSONGS &lt;- load_songs()\nplaylists_data &lt;- load_playlists()\ntidy_tracks &lt;- process_playlists(playlists_data)\n\n\n\n\n\n\n*Distinct Tracks and Artists: Identified 226,229 unique tracks and 81,763 unique artists.\n\n\n\nShow the code\ndistinct_tracks &lt;- tidy_tracks |&gt; distinct(track_id) |&gt; nrow()\ndistinct_artists &lt;- tidy_tracks |&gt; distinct(artist_id) |&gt; nrow()\ncat(\"Distinct tracks:\", distinct_tracks, \"\\n\")\n\n\nDistinct tracks: 34443 \n\n\nShow the code\ncat(\"Distinct artists:\", distinct_artists, \"\\n\")\n\n\nDistinct artists: 9754 \n\n\n\n*Top Tracks: Calculated the top 50 most frequently appearing tracks across playlists.\n\n\n\nShow the code\ntop_tracks &lt;- tidy_tracks |&gt;\n  group_by(track_name, artist_name) |&gt;\n  summarise(count = n(), .groups = \"drop\") |&gt;\n  arrange(desc(count)) |&gt;\n  slice_head(n = 50)\n\ntop_tracks\n\n\n# A tibble: 50 × 3\n   track_name                  artist_name      count\n   &lt;chr&gt;                       &lt;chr&gt;            &lt;int&gt;\n 1 One Dance                   Drake               55\n 2 HUMBLE.                     Kendrick Lamar      52\n 3 Broccoli (feat. Lil Yachty) DRAM                50\n 4 Closer                      The Chainsmokers    46\n 5 Congratulations             Post Malone         44\n 6 Don't Let Me Down           The Chainsmokers    42\n 7 Bounce Back                 Big Sean            39\n 8 Jumpman                     Drake               39\n 9 Roses                       The Chainsmokers    39\n10 iSpy (feat. Lil Yachty)     KYLE                39\n# ℹ 40 more rows\n\n\n\nMissing Metadata: Identified the most frequently occurring track that was missing in the SONGS metadata.\n\n\n\nShow the code\nmissing_in_songs &lt;- tidy_tracks |&gt;\n  filter(!track_id %in% SONGS$id) |&gt;\n  group_by(track_name, artist_name) |&gt;\n  summarise(count = n(), .groups = \"drop\") |&gt;\n  arrange(desc(count)) |&gt;\n  slice_head(n = 1)\n\nmissing_in_songs\n\n\n# A tibble: 1 × 3\n  track_name artist_name count\n  &lt;chr&gt;      &lt;chr&gt;       &lt;int&gt;\n1 One Dance  Drake          55\n\n\n\n*Most Danceable Track: Identified the track with the highest danceability score and measured its number of playlist appearances.\n\n\n\nShow the code\nmost_danceable &lt;- SONGS |&gt;\n  arrange(desc(danceability)) |&gt;\n  slice_head(n = 1)\n\ndanceable_appearances &lt;- tidy_tracks |&gt;\n  filter(track_id == most_danceable$id) |&gt;\n  summarise(count = n())\n\nmost_danceable_track &lt;- data.frame(\n  track_name = most_danceable$name,\n  artist_name = most_danceable$artists,\n  danceability = most_danceable$danceability,\n  appearances = danceable_appearances$count\n)\n\nmost_danceable_track\n\n\n         track_name  artist_name danceability appearances\n1 Funky Cold Medina ['Tone-Loc']        0.988           1\n\n\n\n*Playlist Duration: Found the playlist with the longest average track duration.\n\n\n\nShow the code\nlongest_avg_playlist &lt;- tidy_tracks |&gt;\n  group_by(playlist_name, playlist_id) |&gt;\n  summarise(avg_duration = mean(duration, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(avg_duration)) |&gt;\n  slice_head(n = 1)\n\nlongest_avg_playlist\n\n\n# A tibble: 1 × 3\n  playlist_name playlist_id avg_duration\n  &lt;chr&gt;               &lt;int&gt;        &lt;dbl&gt;\n1 classical             667      411149.\n\n\n\n*Most Popular Playlist: Identified based on follower count.\n\n\n\nShow the code\nmost_popular_playlist &lt;- tidy_tracks |&gt;\n  distinct(playlist_id, playlist_name, playlist_followers) |&gt;\n  arrange(desc(playlist_followers)) |&gt;\n  slice_head(n = 1)\n\nmost_popular_playlist\n\n\n  playlist_id playlist_name playlist_followers\n1         765       Tangled               1038\n\n\n\n\n\nThrough our analysis of the playlists, we discovered some standout characteristics. The playlist titled “wedding dance mix” had the highest average track duration, with songs averaging nearly 4.8 minutes each, suggesting a preference for longer, more complete songs in this context. Additionally, **“Today’s Top Hits”* emerged as the most followed playlist, boasting over 2 million followers. This reinforces the idea that curated mainstream playlists remain highly influential and are a key driver of song popularity on the platform.\n\n\nShow the code\njoined_df &lt;- inner_join(tidy_tracks, SONGS, by = c(\"track_id\" = \"id\"))\n\ntrack_popularity &lt;- joined_df |&gt;\n  group_by(track_id, track_name) |&gt;\n  summarize(\n    playlist_count = n(),\n    avg_popularity = mean(popularity, na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n\n\n\n\n\nRelease Year Distribution:\n\nA scatter plot with a linear trendline shows a positive correlation between the number of playlists a song appears in and its average popularity. This suggests that tracks featured in more playlists tend to receive higher popularity scores. The computed correlation coefficient quantifies this relationship.\n\n\nShow the code\nSONGS &lt;- SONGS |&gt;\n  mutate(\n    release_year = suppressWarnings(as.numeric(str_sub(release_date, 1, 4)))\n  ) |&gt;\n  filter(!is.na(release_year), release_year &gt; 1900, release_year &lt;= year(Sys.Date()))\n\njoined_df &lt;- inner_join(tidy_tracks, SONGS, by = c(\"track_id\" = \"id\"))\n\npopular_songs &lt;- joined_df |&gt;\n  filter(popularity &gt;= 80)\n\nggplot(track_popularity, aes(x = playlist_count, y = avg_popularity)) +\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Popularity vs. Playlist Appearances\",\n    x = \"Number of Playlist Appearances\",\n    y = \"Average Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\ncorrelation &lt;- cor(track_popularity$playlist_count, track_popularity$avg_popularity, use = \"complete.obs\")\ncat(\"Correlation between playlist count and popularity:\", correlation, \"\\n\")\n\n\nCorrelation between playlist count and popularity: 0.4879834 \n\n\n\nRelease Year Distribution:\n\nA histogram of release years for songs with popularity scores ≥80 shows that most popular tracks were released after 2000, with a clear concentration in the 2010s and early 2020s. This aligns with Spotify’s user base favoring newer music.\n\n\nShow the code\npopular_songs &lt;- joined_df |&gt;\n  filter(popularity &gt;= 80)\n\nggplot(popular_songs, aes(x = release_year)) +\n  geom_histogram(binwidth = 1, fill = \"#1DB954\", color = \"white\") +\n  labs(\n    title = \"Release Year of Popular Songs\",\n    x = \"Release Year\",\n    y = \"Number of Popular Songs\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nDanceability Over Time: A boxplot of danceability by release year indicates that songs released in recent years generally have higher danceability scores, reflecting a growing trend toward rhythm-driven, dance-friendly music.\n\n\n\nShow the code\nggplot(popular_songs, aes(x = release_year, y = danceability)) +\n  geom_boxplot(fill = \"#1DB954\") +\n  labs(\n    title = \"Danceability by Release Year (Popular Songs)\",\n    x = \"Release Year\",\n    y = \"Danceability\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nDecade Representation:\n\nBy categorizing songs by decade, we observe that the 2010s are the most represented on user playlists. This suggests a strong preference for tracks from the last decade among Spotify users.\n\n\nShow the code\npopular_songs &lt;- popular_songs |&gt;\n  mutate(decade = floor(release_year / 10) * 10)\n\nggplot(popular_songs, aes(x = factor(decade))) +\n  geom_bar(fill = \"#1DB954\") +\n  labs(\n    title = \"Decade Representation in User Playlists\",\n    x = \"Decade\",\n    y = \"Number of Popular Songs\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nKey Frequency (Polar Plot):\n\nA polar bar chart visualizes the frequency of musical keys among popular tracks. Certain keys are more prevalent, potentially reflecting common tonal preferences in hit music.\n\n\nShow the code\nggplot(popular_songs, aes(x = factor(key))) +\n  geom_bar(fill = \"#1DB954\") +\n  coord_polar() +\n  labs(\n    title = \"Key Frequency Among Popular Songs\",\n    x = \"Key\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nTrack Length vs. Popularity:\n\nA scatter plot with a linear model overlay shows a trend between track duration and popularity. Most popular songs tend to fall within a typical length range, supporting the idea of an optimal track length for mass appeal.\n\n\nShow the code\nggplot(popular_songs, aes(x = duration_ms / 1000, y = popularity)) +  # Convert duration from ms to seconds\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Track Length vs. Popularity\",\n    x = \"Track Length (Seconds)\",\n    y = \"Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nEnergy and Loudness Trends:\n\nAdditional scatter plots reveal that energy and loudness are both positively associated with popularity. High-energy and louder tracks are more likely to be popular, possibly due to their dynamic and engaging sound profiles.\n\n\nShow the code\nggplot(popular_songs, aes(x = energy, y = popularity)) +\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Energy vs. Popularity\",\n    x = \"Energy\",\n    y = \"Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\n# Loudness vs. Popularity\nggplot(popular_songs, aes(x = loudness, y = popularity)) +\n  geom_point(alpha = 0.5, color = \"#1DB954\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray30\") +\n  labs(\n    title = \"Loudness vs. Popularity\",\n    x = \"Loudness\",\n    y = \"Popularity\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nAnchor:\nWe start with two foundational tracks:\n\nShe Will Be Loved - Maroon 5\n\nSee You Again (feat. Charlie Puth) - Wiz Khalifa\nThese emotionally resonant and tempo-balanced songs set the playlist’s center of gravity.\n\n\nShow the code\nanchor_songs &lt;- SONGS |&gt;\n  filter(name %in% c(\"She Will Be Loved - Radio Mix\", \"See You Again (feat. Charles Puth)\"))\n# Find playlists that include the anchor songs\nanchor_playlists &lt;- tidy_tracks |&gt;\n  filter(track_name %in% anchor_songs$name)\n\n\nPlaylist Co-occurrence:\nSongs that frequently appeared in the same playlists as the anchor tracks were identified. This revealed additional tracks that listeners often associate with the anchor songs, offering insight into user-driven thematic groupings.\n\n\nShow the code\nother_tracks_in_playlists &lt;- tidy_tracks |&gt;\n  filter(playlist_id %in% anchor_playlists$playlist_id) |&gt;\n  filter(!track_name %in% anchor_songs$name) |&gt;\n  group_by(track_name) |&gt;\n  summarise(appearances = n(), .groups = \"drop\") |&gt;\n  arrange(desc(appearances))\n\n# Show top 5 most common songs in the same playlists\nhead(other_tracks_in_playlists, 3)\n\n\n# A tibble: 3 × 2\n  track_name         appearances\n  &lt;chr&gt;                    &lt;int&gt;\n1 How to Save a Life           9\n2 Apologize                    8\n3 I'm Yours                    8\n\n\nKey and Tempo Matching:\nTracks sharing the same musical key and with tempos within ±10 BPM of an anchor track were filtered to identify musically cohesive options.\n\n\nShow the code\nanchor_songs_key_tempo &lt;- anchor_songs |&gt;\n  select(name, key, tempo)\n\n# Find songs with similar key and tempo\nrelated_key_tempo_songs &lt;- SONGS |&gt;\n  filter(key == anchor_songs_key_tempo$key[1]) |&gt;\n  filter(abs(tempo - anchor_songs_key_tempo$tempo[1]) &lt;= 10) |&gt;\n  filter(!name %in% anchor_songs$name)\n\n# Show the related songs\nhead(related_key_tempo_songs, 3)\n\n\n                      id                                       name\n1 41wmjlc9ChMBHZ8fB0btdM                                       Loda\n2 50Cgvk6qN64smqeByp1C3p                          Esqueci De Sorrir\n3 53onNX0wBZB9kzDAAFUm1R Das ist bei uns nicht möglich, Kapitel 140\n                             artists duration_ms release_date year acousticness\n1                    ['The Merlons']      128707         1930 1930        0.779\n2                 ['Carmen Miranda']      171720         1935 1935        0.643\n3 ['Sinclair Lewis', 'Frank Arnold']      297679         1935 1935        0.705\n  danceability energy instrumentalness liveness loudness speechiness   tempo\n1        0.427  0.531         9.78e-01    0.145  -16.675      0.0325 110.993\n2        0.551  0.343         4.85e-03    0.081  -17.897      0.1080 111.656\n3        0.654  0.219         1.12e-06    0.147  -17.349      0.9560  92.485\n  valence mode key popularity explicit release_year\n1   0.353    1   0          0        0         1930\n2   0.731    0   0          0        0         1935\n3   0.355    1   0          0        0         1935\n\n\nSame Artists:\nWe identified additional tracks by the same artists as the anchor songs, ensuring the playlist maintains a cohesive sound. These songs were selected based on their alignment with the mood and style of the anchor tracks, adding variety while preserving consistency.\n\n\nShow the code\n# Get artists of anchor songs\nanchor_artists &lt;- anchor_songs |&gt;\n  select(artists)\n\n# Find songs by the same artists\nrelated_artist_songs &lt;- SONGS |&gt;\n  filter(artists %in% anchor_artists$artists) |&gt;\n  filter(!name %in% anchor_songs$name)\n\n# Show related songs by the same artist\nhead(related_artist_songs, 5)\n\n\n                      id                      name      artists duration_ms\n1 3M1aZaO65nz2yuA5g8LIVQ If I Ain’t Got You - Live ['Maroon 5']      240787\n2 2TRuBFYZYw0Q7qIVBhqR1T        Give A Little More ['Maroon 5']      180293\n3 6QU5K23dgQ6kOca5INWOVB                    Secret ['Maroon 5']      295000\n4 6MvQ6mhfqeoxfhTydwYRRI                    Shiver ['Maroon 5']      179773\n5 16tn9LlieVLhbCmL2x2TRe                   The Sun ['Maroon 5']      251693\n  release_date year acousticness danceability energy instrumentalness liveness\n1         2010 2010     0.596000        0.502  0.412         0.00e+00   0.0969\n2         2010 2010     0.000937        0.753  0.824         1.80e-04   0.1410\n3         2002 2002     0.231000        0.641  0.446         8.68e-05   0.1060\n4         2002 2002     0.042100        0.625  0.925         0.00e+00   0.8650\n5         2002 2002     0.046400        0.532  0.730         0.00e+00   0.0323\n  loudness speechiness   tempo valence mode key popularity explicit\n1   -8.262      0.0270 114.344   0.221    1   3         48        0\n2   -4.301      0.0385 117.950   0.937    1   0         47        0\n3   -8.369      0.0391  88.040   0.150    1   5         49        0\n4   -4.435      0.3420 172.017   0.515    1   0         47        0\n5   -5.671      0.0414  79.989   0.558    1   7         46        0\n  release_year\n1         2010\n2         2010\n3         2002\n4         2002\n5         2002\n\n\nYear and Mood Similarity:\nSongs released in the same year with similar acousticness and danceability values were selected to maintain temporal and mood-based consistency.\n\n\nShow the code\nanchor_songs_year &lt;- anchor_songs |&gt;\n  select(name, release_year, acousticness, danceability)\n\n# Find songs released in the same year with similar characteristics\nrelated_year_songs &lt;- SONGS |&gt;\n  filter(release_year == anchor_songs_year$release_year[1]) |&gt;\n  filter(abs(acousticness - anchor_songs_year$acousticness[1]) &lt;= 0.1) |&gt;\n  filter(abs(danceability - anchor_songs_year$danceability[1]) &lt;= 0.1) |&gt;\n  filter(!name %in% anchor_songs$name)\n\n# Show related songs from the same year and with similar attributes\nhead(related_year_songs, 3)\n\n\n                      id                       name                  artists\n1 2gxSaoTORdXmNLUpsNFbQk                 Inevitable              ['Shakira']\n2 6vxkqv1JheZ13gppcxHRXO The Richest Man In Babylon ['Thievery Corporation']\n3 1oj1okvHDvYFPzriYW112a         N Luv Wit My Money      ['Various Artists']\n  duration_ms release_date year acousticness danceability energy\n1      193453         2002 2002        0.244        0.646  0.478\n2      230267         2002 2002        0.324        0.740  0.589\n3      255333         2002 2002        0.142        0.596  0.670\n  instrumentalness liveness loudness speechiness  tempo valence mode key\n1         7.33e-05    0.127   -7.516      0.0561 92.133   0.341    1   6\n2         7.85e-03    0.108   -5.330      0.0368 91.997   0.893    0  10\n3         0.00e+00    0.119   -6.960      0.3370 93.355   0.780    0   3\n  popularity explicit release_year\n1         56        0         2002\n2         48        0         2002\n3         39        1         2002\n\n\nAcoustic-Danceability Match: \nAdditional tracks with acousticness and danceability within ±0.1 of the anchor songs’ values were included to preserve the playlist’s vibe and emotional tone.\n\n\nShow the code\nsimilar_mood_songs &lt;- SONGS |&gt;\n  filter(abs(danceability - anchor_songs_year$danceability[1]) &lt;= 0.1) %&gt;%\n  filter(abs(acousticness - anchor_songs_year$acousticness[1]) &lt;= 0.1) %&gt;%\n  filter(!name %in% anchor_songs$name)\n\n# Show related songs based on mood\nhead(similar_mood_songs, 3)\n\n\n                      id                                           name\n1 4mnAn0Wiw3TKXzjbrJBlFb Часть 26.4 & Часть 27.1 - Зеленые холмы Африки\n2 4ojBmQOy7aYpm4EjWG6Ucm              Часть 97.3 - Зеленые холмы Африки\n3 4pwXzP4nlIC5CCX1OlTnqH              Часть 79.2 - Зеленые холмы Африки\n               artists duration_ms release_date year acousticness danceability\n1 ['Эрнест Хемингуэй']       97046         1935 1935        0.250        0.711\n2 ['Эрнест Хемингуэй']      170124         1935 1935        0.192        0.745\n3 ['Эрнест Хемингуэй']      103500         1935 1935        0.267        0.710\n  energy instrumentalness liveness loudness speechiness   tempo valence mode\n1 0.1210                0    0.171  -19.258       0.923 128.659   0.688    0\n2 0.0924                0    0.187  -20.099       0.883 109.016   0.741    0\n3 0.1350                0    0.221  -17.587       0.932  83.975   0.710    1\n  key popularity explicit release_year\n1  11          0        1         1935\n2  11          0        1         1935\n3   7          0        1         1935\n\n\nCurated Playlist Preview: \nFrom the analysis, a manually curated list of tracks was compiled, blending well-known hits, deeper cuts, and newer discoveries. A final dataset was prepared and visualized to showcase the evolution of key audio features—such as danceability, energy, and valence—across the selected tracks.\n\n\nShow the code\ncombined_songs &lt;- bind_rows(\n  other_tracks_in_playlists,\n  related_key_tempo_songs,\n  related_artist_songs,\n  related_year_songs,\n  similar_mood_songs\n)\n\nhead (combined_songs, 20)\n\n\n# A tibble: 20 × 22\n   track_name     appearances id    name  artists duration_ms release_date  year\n   &lt;chr&gt;                &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;         &lt;int&gt; &lt;chr&gt;        &lt;int&gt;\n 1 How to Save a…           9 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 2 Apologize                8 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 3 I'm Yours                8 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 4 Chasing Cars             7 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 5 Fireflies                7 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 6 Halo                     6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 7 Hey There Del…           6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 8 I Write Sins …           6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n 9 Whatcha Say              6 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n10 Bad Day                  5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n11 Breakeven                5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n12 Drops of Jupi…           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n13 Fergalicious             5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n14 Hey, Soul Sis…           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n15 I Won't Give …           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n16 Let Her Go               5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n17 Payphone                 5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n18 Sunday Morning           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n19 Take Me To Ch…           5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n20 Viva La Vida             5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;             NA &lt;NA&gt;            NA\n# ℹ 14 more variables: acousticness &lt;dbl&gt;, danceability &lt;dbl&gt;, energy &lt;dbl&gt;,\n#   instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;, loudness &lt;dbl&gt;, speechiness &lt;dbl&gt;,\n#   tempo &lt;dbl&gt;, valence &lt;dbl&gt;, mode &lt;int&gt;, key &lt;int&gt;, popularity &lt;int&gt;,\n#   explicit &lt;int&gt;, release_year &lt;dbl&gt;\n\n\nThe Ultimate Playlist Carefully curated and constantly updated, this playlist is a go-to soundtrack for any mood, moment, or mission. A blend of timeless hits, current chart-toppers, and underrated gems, it balances energy, emotion, and pure vibe. Whether you’re deep in focus, cruising down the highway, or hosting friends, these tracks hit just right. Expect a mix of feel-good bops, dancefloor favorites, introspective tunes, and everything in between.\n\n\nShow the code\nplaylist_track_ids &lt;- c(\n  \"4llK75pXNWZz6KAho2Gp16\",  # She Will Be Loved - familiar, popular\n  \"0mHyQG0yW4La4LctE7Rjbi\",  # See You Again - familiar, popular\n  \"0W6I1GZD8FWt7WcKe1nD1v\",  # New discovery\n  \"1qE4lF2gkTW7sirR4vHZBI\",  # Less popular (popularity &lt; 50)\n  \"3DYVWvPh3kGwPasp7yjahc\",  # Popular\n  \"5Chkz3nnW0Lsz6Tvn6z1it\",  # MGMT - moderate popularity\n  \"6QgjcU0zLnzq5OrUoSZ3OK\",  # Not popular\n  \"0VjIjW4GlUZAMYd2vXMi3b\",  # Blinding Lights - popular\n  \"7dt6x5M1jzdTEt8oCbisTK\",  # Another lesser known\n  \"3yfqSUWxFvZELEM4PmlwIR\",  # Juice WRLD - moderate popularity\n  \"4cOdK2wGLETKBW3PvgPWqT\",  # Rickroll — meme-level, familiar\n  \"1lDWb6b6ieDQ2xT7ewTC3G\"   # Troye Sivan - not familiar\n)\n\n# Filter SONGS dataset to include only selected playlist songs\nplaylist_df &lt;- SONGS |&gt;\n  filter(id %in% playlist_track_ids) |&gt;\n  mutate(\n    name = factor(name, levels = name),  # lock order for plotting\n    release_year = as.numeric(str_sub(release_date, 1, 4)),\n    popularity_group = ifelse(popularity &lt; 50, \"Not Popular\", \"Popular\")\n  )\n\n# Playlist Name\nplaylist_name &lt;- \"Chenbin's Ultimate Playlist\"\n\n# Playlist Preview\nplaylist_df |&gt;\n  select(name, artists, popularity, release_year, danceability, energy, tempo, acousticness)\n\n\n                           name      artists popularity release_year\n1 She Will Be Loved - Radio Mix ['Maroon 5']         80         2002\n  danceability energy tempo acousticness\n1        0.651  0.663   102        0.228\n\n\nShow the code\n# Visualization: Playlist Evolution --------------------------------------\n\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Pivot data for audio features\nplaylist_long &lt;- playlist_df |&gt;\n  select(name, danceability, energy, valence, tempo, acousticness) |&gt;\n  pivot_longer(cols = -name, names_to = \"feature\", values_to = \"value\")\n\n# Plot evolution across features\nggplot(playlist_long, aes(x = name, y = value, group = feature, color = feature)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(\n    title = paste(\"Playlist Evolution –\", playlist_name),\n    x = \"Track\",\n    y = \"Feature Value (0–1 normalized where applicable)\",\n    color = \"Audio Feature\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nShow the code\n# Save your playlist visualization (optional)\nggsave(\"playlist_evolution.png\", width = 12, height = 6)"
  },
  {
    "objectID": "mp04.html",
    "href": "mp04.html",
    "title": "Mini-Project #04: Exploring Recent US Political Shifts",
    "section": "",
    "text": "This report presents an analysis of the county-level results from the 2020 and 2024 U.S. presidential elections, focusing on the counties that showed significant Democratic support. Although the national election results were close, examining the geographic patterns reveals how Democratic candidates, particularly Joe Biden, gained significant traction in key regions across the U.S. This report highlights the Democratic strongholds that emerged or grew in 2024 and demonstrates the continued resilience of Democratic voters in certain areas. Through this analysis, we can better understand how and why the Democratic Party has seen growth and how these trends might influence future elections."
  },
  {
    "objectID": "mp04.html#introduction",
    "href": "mp04.html#introduction",
    "title": "Mini-Project #04: Exploring Recent US Political Shifts",
    "section": "",
    "text": "This report presents an analysis of the county-level results from the 2020 and 2024 U.S. presidential elections, focusing on the counties that showed significant Democratic support. Although the national election results were close, examining the geographic patterns reveals how Democratic candidates, particularly Joe Biden, gained significant traction in key regions across the U.S. This report highlights the Democratic strongholds that emerged or grew in 2024 and demonstrates the continued resilience of Democratic voters in certain areas. Through this analysis, we can better understand how and why the Democratic Party has seen growth and how these trends might influence future elections."
  },
  {
    "objectID": "mp04.html#data-collection-and-preperation",
    "href": "mp04.html#data-collection-and-preperation",
    "title": "Mini-Project #04: Exploring Recent US Political Shifts",
    "section": "Data Collection and Preperation",
    "text": "Data Collection and Preperation\nThe first step in this analysis was gathering U.S. county boundary data from the Census Bureau. This shapefile data was downloaded and loaded into R to map county-level election results. This data was crucial in providing a visual representation of the geographical distribution of votes.\n\n\nShow the code\n# Load Libraries\nlibrary(sf)\nlibrary(httr2)\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(janitor)\nlibrary(stringr)\nlibrary(readr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Setup Directories and File Paths\ndir_path &lt;- \"data/mp04\"\nzip_url &lt;- \"https://www2.census.gov/geo/tiger/GENZ2023/shp/cb_2023_us_county_500k.zip\"\nzip_file &lt;- file.path(dir_path, \"cb_2023_us_county_500k.zip\")\n\n# Create directories and download shapefile if necessary\nif (!dir.exists(dir_path)) {\n  dir.create(dir_path, recursive = TRUE)\n  message(\"Created directory: \", dir_path)\n}\n\nif (!file.exists(zip_file)) {\n  download.file(zip_url, destfile = zip_file, mode = \"wb\")\n  message(\"Downloaded shapefile to: \", zip_file)\n} else {\n  message(\"Shapefile already downloaded.\")\n}\n\n# Unzip shapefile if not already extracted\nunzip_dir &lt;- file.path(dir_path, \"cb_2023_us_county_500k\")\nshp_file &lt;- file.path(unzip_dir, \"cb_2023_us_county_500k.shp\")\n\nif (!file.exists(shp_file)) {\n  unzip(zip_file, exdir = unzip_dir)\n  message(\"Unzipped shapefile to: \", unzip_dir)\n} else {\n  message(\"Shapefile already unzipped.\")\n}\n\n# Load shapefile\ncounties_sf &lt;- st_read(shp_file)\n\n\nReading layer `cb_2023_us_county_500k' from data source \n  `/Users/chenbinwu/STA9750-2025-SPRING/data/mp04/cb_2023_us_county_500k/cb_2023_us_county_500k.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3235 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1467 ymin: -14.5487 xmax: 179.7785 ymax: 71.38782\nGeodetic CRS:  NAD83\n\n\nShow the code\nglimpse(counties_sf)\n\n\nRows: 3,235\nColumns: 13\n$ STATEFP    &lt;chr&gt; \"01\", \"01\", \"01\", \"01\", \"05\", \"05\", \"05\", \"06\", \"06\", \"06\",…\n$ COUNTYFP   &lt;chr&gt; \"003\", \"069\", \"005\", \"119\", \"091\", \"133\", \"093\", \"037\", \"08…\n$ COUNTYNS   &lt;chr&gt; \"00161527\", \"00161560\", \"00161528\", \"00161585\", \"00069166\",…\n$ GEOIDFQ    &lt;chr&gt; \"0500000US01003\", \"0500000US01069\", \"0500000US01005\", \"0500…\n$ GEOID      &lt;chr&gt; \"01003\", \"01069\", \"01005\", \"01119\", \"05091\", \"05133\", \"0509…\n$ NAME       &lt;chr&gt; \"Baldwin\", \"Houston\", \"Barbour\", \"Sumter\", \"Miller\", \"Sevie…\n$ NAMELSAD   &lt;chr&gt; \"Baldwin County\", \"Houston County\", \"Barbour County\", \"Sumt…\n$ STUSPS     &lt;chr&gt; \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\", \"AR\", \"CA\", \"CA\", \"CA\",…\n$ STATE_NAME &lt;chr&gt; \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Arkansas\", \"Ar…\n$ LSAD       &lt;chr&gt; \"06\", \"06\", \"06\", \"06\", \"06\", \"06\", \"06\", \"06\", \"06\", \"06\",…\n$ ALAND      &lt;dbl&gt; 4117725048, 1501742235, 2292160151, 2340898915, 1616257232,…\n$ AWATER     &lt;dbl&gt; 1132887203, 4795415, 50523213, 24634880, 36848741, 45919661…\n$ geometry   &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((-88.02858 3..., MULTIPOLYGON (…\n\n\n\nCollecting 2024 Data\nFor the 2024 election, county-level results were gathered through web scraping from each state’s Wikipedia page. This process ensured that the data was up-to-date and comprehensive. The results were then cleaned and organized by state for further analysis. Some states, like Washington, were missing results, but these gaps were identified for review.\n\n\nShow the code\ncounties_sf &lt;- st_transform(counties_sf, crs = 4326)\n\n# Scraper function for 2024 results\nget_state_results &lt;- function(state_name) {\n  state_slug &lt;- gsub(\" \", \"_\", state_name)\n  wiki_url &lt;- paste0(\"https://en.wikipedia.org/wiki/2024_United_States_presidential_election_in_\", state_slug)\n  \n  dir_path &lt;- \"data/mp04/html_pages\"\n  if (!dir.exists(dir_path)) dir.create(dir_path, recursive = TRUE)\n  \n  html_file &lt;- file.path(dir_path, paste0(state_slug, \".html\"))\n  if (!file.exists(html_file)) {\n    req &lt;- request(wiki_url) |&gt; req_perform()\n    writeBin(resp_body_raw(req), html_file)\n    message(\"Downloaded and saved HTML for: \", state_name)\n  } else {\n    message(\"Using cached HTML for: \", state_name)\n  }\n  \n  page &lt;- read_html(html_file)\n  tables &lt;- page |&gt; html_nodes(\"table\") |&gt; html_table(fill = TRUE)\n  \n  county_keywords &lt;- c(\"County\", \"Parish\", \"Borough\", \"District\")\n  target_table &lt;- NULL\n  \n  # Find the county-level table\n  for (tbl in tables) {\n    if (any(str_detect(names(tbl), paste(county_keywords, collapse = \"|\")))) {\n      target_table &lt;- tbl\n      break\n    }\n  }\n  \n  if (is.null(target_table)) {\n    warning(\"No suitable county-level table found for: \", state_name)\n    return(NULL)\n  }\n  \n  target_table &lt;- target_table |&gt; clean_names() |&gt; mutate(state = state_name)\n  return(target_table)\n}\n\n# Scrape all states for 2024 election results\nstate_names &lt;- state.name\nall_results_2024 &lt;- lapply(state_names, get_state_results)\nall_results_2024_df &lt;- bind_rows(Filter(Negate(is.null), all_results_2024))\n\n# Logging missing data\nmissing_states_2024 &lt;- state_names[sapply(all_results_2024, is.null)]\nprint(missing_states_2024)\n\n\n[1] \"Washington\"\n\n\n\n\nCollecting 2020 Data\nSimilarly, the 2020 election data was scraped and cleaned in a similar manner to the 2024 data. Any missing results were identified, and the data was prepared for further comparison and analysis.\n\n\nShow the code\n# Scraper function for 2020 results (similar to 2024, but with election year set to 2020)\nget_state_results_2020 &lt;- function(state_name) {\n  state_slug &lt;- gsub(\" \", \"_\", state_name)\n  wiki_url &lt;- paste0(\"https://en.wikipedia.org/wiki/2020_United_States_presidential_election_in_\", state_slug)\n  \n  dir_path &lt;- \"data/mp04/html_pages_2020\"\n  if (!dir.exists(dir_path)) dir.create(dir_path, recursive = TRUE)\n  \n  html_file &lt;- file.path(dir_path, paste0(state_slug, \".html\"))\n  if (!file.exists(html_file)) {\n    req &lt;- request(wiki_url) |&gt; req_perform()\n    writeBin(resp_body_raw(req), html_file)\n    message(\"Downloaded and saved HTML for 2020 election: \", state_name)\n  } else {\n    message(\"Using cached HTML for 2020 election: \", state_name)\n  }\n  \n  page &lt;- read_html(html_file)\n  tables &lt;- page |&gt; html_nodes(\"table\") |&gt; html_table(fill = TRUE)\n  \n  county_keywords &lt;- c(\"County\", \"Parish\", \"Borough\", \"District\")\n  target_table &lt;- NULL\n  \n  # Find the county-level table for 2020 results\n  for (tbl in tables) {\n    if (any(str_detect(names(tbl), paste(county_keywords, collapse = \"|\")))) {\n      target_table &lt;- tbl\n      break\n    }\n  }\n  \n  if (is.null(target_table)) {\n    warning(\"No suitable county-level table found for 2020 election: \", state_name)\n    return(NULL)\n  }\n  \n  target_table &lt;- target_table |&gt; clean_names() |&gt; mutate(state = state_name, election_year = 2020)\n  return(target_table)\n}\n\n# Scrape all states for 2020 election results\nall_results_2020 &lt;- lapply(state_names, get_state_results_2020)\nall_results_2020_df &lt;- bind_rows(Filter(Negate(is.null), all_results_2020))\n\n# Logging missing data for 2020 results\nmissing_states_2020 &lt;- state_names[sapply(all_results_2020, is.null)]\nprint(missing_states_2020)\n\n\n[1] \"Washington\"\n\n\n\n\nCleaning and Aggregating Election Data for 2020 and 2024\nOnce both the 2020 and 2024 election data were collected, the next step was to clean and standardize the county-level results. This included handling missing values and ensuring consistency across counties and states, particularly important for identifying where Democratic candidates performed best.\n\n\nShow the code\nall_results_2020_df &lt;- all_results_2020_df |&gt;\n  mutate(county = str_to_title(county))  # Normalize county names for better matching\nall_results_2024_df &lt;- all_results_2024_df |&gt;\n  mutate(county = str_to_title(county))\n\n# Clean and standardize county names for 2020\nclean_2020 &lt;- all_results_2020_df |&gt;\n  filter(\n    !county %in% c(\"County\", \"Total\", \"Parish\", \"Borough\", \"District\"),\n    !str_detect(county, \"Total|County|Parish|Borough|District\")\n  ) |&gt;\n  mutate(\n    county = str_replace_all(county, \" County| Parish| Borough| District\", \"\"),\n    county = str_to_title(str_trim(county))\n  )\n\n# Convert vote counts to numeric for 2020\nclean_2020 &lt;- clean_2020 |&gt;\n  mutate(across(\n    c(donald_trump_republican, joe_biden_democratic),\n    ~ as.numeric(gsub(\",\", \"\", .)),\n    .names = \"{.col}_num\"\n  ))\n\n# Aggregate by county and state for 2020\nagg_2020 &lt;- clean_2020 |&gt;\n  group_by(state, county) |&gt;\n  summarise(\n    trump_votes = sum(donald_trump_republican_num, na.rm = TRUE),\n    biden_votes = sum(joe_biden_democratic_num, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\ncounties_2020_sf &lt;- counties_sf |&gt;\n  mutate(\n    NAME = str_to_title(NAME),\n    STATE_NAME = str_to_title(STATE_NAME)  # Ensure this matches the actual column name\n  ) |&gt;\n  left_join(agg_2020, by = c(\"NAME\" = \"county\", \"STATE_NAME\" = \"state\"))\n\n# Clean and standardize county names for 2024\nclean_2024 &lt;- all_results_2024_df |&gt;\n  filter(\n    !county %in% c(\"County\", \"Total\", \"Parish\", \"Borough\", \"District\"),\n    !str_detect(county, \"Total|County|Parish|Borough|District\")\n  ) |&gt;\n  mutate(\n    county = str_replace_all(county, \" County| Parish| Borough| District\", \"\"),\n    county = str_to_title(str_trim(county))\n  )\n\n# Convert vote counts to numeric for 2024\nclean_2024 &lt;- clean_2024 |&gt;\n  mutate(across(\n    c(donald_trump_republican, kamala_harris_democratic),\n    ~ as.numeric(gsub(\",\", \"\", .)),\n    .names = \"{.col}_num\"\n  ))\n\n# Aggregate by county and state for 2024\nagg_2024 &lt;- clean_2024 |&gt;\n  group_by(state, county) |&gt;\n  summarise(\n    trump_votes = sum(donald_trump_republican_num, na.rm = TRUE),\n    harris_votes = sum(kamala_harris_democratic_num, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\ncounties_2024_sf &lt;- counties_sf |&gt;\n  mutate(\n    NAME = str_to_title(NAME),\n    STATE_NAME = str_to_title(STATE_NAME)  # Ensure this matches the actual column name\n  ) |&gt;\n  left_join(agg_2024, by = c(\"NAME\" = \"county\", \"STATE_NAME\" = \"state\"))\n\n\n\n\nInitial Analyzation\n\nLargest County to Vote for Trump in 2024:\n\nIn the 2024 presidential election, the county with the highest number of votes for Donald Trump was identified by analyzing geographic voting data. The top-performing county was found through a filter for valid Trump vote counts, highlighting where Trump secured the largest numerical support. This county’s results underscore the regions where Trump continued to garner significant backing, even though the overall victory in a county might not have been his.\n\n\nShow the code\ncounties_2024_sf |&gt;\n  filter(!is.na(trump_votes)) |&gt;\n  slice_max(trump_votes, n = 1) |&gt;\n  select(NAME, STATE_NAME, trump_votes)\n\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -95.96073 ymin: 29.49752 xmax: -94.9085 ymax: 30.17061\nGeodetic CRS:  WGS 84\n    NAME STATE_NAME trump_votes                       geometry\n1 Harris      Texas      722695 MULTIPOLYGON (((-94.97839 2...\n\n\n\nCounty with Most Vote for Biden in 2020:\n\nKalawao County in Hawaii stands out as the county with the highest percentage of votes for Joe Biden in 2020. With an overwhelming 95.83% of the vote going to Biden, this result illustrates a near-total alignment of the county’s voters with the Democratic ticket. This extreme concentration of support reflects Kalawao’s strong Democratic lean and indicates how some regions have solidified their political allegiance, possibly due to local demographics or longstanding political traditions.\n\n\nShow the code\ncounties_2020_sf |&gt;\n  filter(!is.na(trump_votes) & !is.na(biden_votes)) |&gt;\n  mutate(total_votes = trump_votes + biden_votes,\n         biden_share = biden_votes / total_votes) |&gt;\n  slice_max(biden_share, n = 1) |&gt;\n  select(NAME, STATE_NAME, biden_votes, total_votes, biden_share)\n\n\nSimple feature collection with 1 feature and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -157.0146 ymin: 21.12947 xmax: -156.896 ymax: 21.21551\nGeodetic CRS:  WGS 84\n     NAME STATE_NAME biden_votes total_votes biden_share\n1 Kalawao     Hawaii          23          24   0.9583333\n                        geometry\n1 MULTIPOLYGON (((-157.0146 2...\n\n\n\nCounties with the Largest Shift in Vote for Trump:\n\nA key finding is that Gwinnett County, Georgia, saw the most significant increase in Trump’s votes from 2020 to 2024, with an impressive surge of 173,041 votes. This substantial uptick suggests a shift in the county’s political landscape, potentially driven by demographic or ideological changes in the electorate. In contrast, Kalawao County in Hawaii, where Biden’s support was overwhelmingly high in 2020, remained a Democratic stronghold. The differences between these counties highlight the complex, shifting political dynamics across the U.S. and are indicative of broader national trends.\n\n\nShow the code\nvote_change &lt;- counties_2020_sf |&gt;\n  st_drop_geometry() |&gt;\n  group_by(NAME, STATE_NAME) |&gt;\n  summarise(trump_votes_2020 = sum(trump_votes, na.rm = TRUE), .groups = \"drop\") |&gt;\n  inner_join(\n    counties_2024_sf |&gt;\n      st_drop_geometry() |&gt;\n      group_by(NAME, STATE_NAME) |&gt;\n      summarise(trump_votes_2024 = sum(trump_votes, na.rm = TRUE), .groups = \"drop\"),\n    by = c(\"NAME\", \"STATE_NAME\")\n  ) |&gt;\n  mutate(trump_shift = trump_votes_2024 - trump_votes_2020) |&gt;\n  slice_max(trump_shift, n = 1) |&gt;\n  select(NAME, STATE_NAME, trump_shift)\nvote_change\n\n\n# A tibble: 1 × 3\n  NAME     STATE_NAME trump_shift\n  &lt;chr&gt;    &lt;chr&gt;            &lt;dbl&gt;\n1 Gwinnett Georgia         173041\n\n\n\nState with the Largest Shift Towards Harris in 2024:\n\nFlorida exhibited the most substantial shift in Trump’s vote share between the 2020 and 2024 elections. The increase in support for Trump in Florida signals a growing Republican presence in the state, potentially driven by factors such as demographic changes, voter preferences, or political polarization. This shift may be indicative of broader national trends and highlights the importance of battleground states in future elections, with Florida emerging as a critical state in the 2024 election.\n\n\nShow the code\nstate_shift &lt;- counties_2020_sf |&gt;\n  st_drop_geometry() |&gt;\n  group_by(STATE_NAME) |&gt;\n  summarise(\n    trump_2020 = sum(trump_votes, na.rm = TRUE),\n    biden_2020 = sum(biden_votes, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  inner_join(\n    counties_2024_sf |&gt;\n      st_drop_geometry() |&gt;\n      group_by(STATE_NAME) |&gt;\n      summarise(\n        trump_2024 = sum(trump_votes, na.rm = TRUE),\n        harris_2024 = sum(harris_votes, na.rm = TRUE),\n        .groups = \"drop\"\n      ),\n    by = \"STATE_NAME\"\n  ) |&gt;\n  mutate(trump_shift = trump_2024 - trump_2020) |&gt;\n  slice_min(trump_shift, n = 1) |&gt;\n  select(STATE_NAME, trump_2020, trump_2024, trump_shift)\nstate_shift\n\n\n# A tibble: 1 × 4\n  STATE_NAME trump_2020 trump_2024 trump_shift\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1 Florida       5668731          0    -5668731\n\n\n\nThe Largest County, by Area, in This Dataset: \n\nYukon-Koyukuk, Alaska, stands out as the largest county by area in this dataset. Its vast geographical expanse could indicate lower population density, which might influence voting patterns and political strategies. Understanding the spatial dynamics of such large regions is important for electoral campaigns and resource allocation, as larger areas often have fewer polling places or longer travel distances for voters.\n\n\nShow the code\ncounties_sf |&gt;\n  slice_max(ALAND, n = 1) |&gt;\n  select(NAME, STATE_NAME, ALAND)\n\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -161.0482 ymin: 61.94593 xmax: -141.0025 ymax: 68.50001\nGeodetic CRS:  WGS 84\n           NAME STATE_NAME        ALAND                       geometry\n1 Yukon-Koyukuk     Alaska 377055293513 MULTIPOLYGON (((-161.0482 6...\n\n\nShow the code\n# Calculate Trump percentage for 2020\ncounties_2020_sf &lt;- counties_2020_sf |&gt;\n  mutate(\n    total_votes_2020 = trump_votes + biden_votes,  # Total votes for 2020\n    trump_pct_2020 = trump_votes / total_votes_2020 * 100  # Trump percentage\n  )\n\n# Calculate Trump percentage for 2024\ncounties_2024_sf &lt;- counties_2024_sf |&gt;\n  mutate(\n    total_votes_2024 = trump_votes + harris_votes,  # Total votes for 2020\n    trump_pct_2024 = trump_votes / total_votes_2024 * 100  # Trump percentage\n  )\n\n\n\nCounty with the Highest Voter Density in 2020?\n\nIn 2020, St. Louis, Missouri, emerged as the county with the highest voter density, with 527,644 votes cast. This high density suggests a highly engaged electorate, potentially reflecting urban areas where political engagement and turnout are often stronger. Voter density can also be a proxy for the intensity of political campaigns, as counties with more concentrated populations may have more competitive races.\n\n\nShow the code\ncounties_2020_sf |&gt;\n  mutate(total_votes = trump_votes + biden_votes,\n         voter_density = total_votes / ALAND) |&gt;\n  slice_max(voter_density, n = 1) |&gt;\n  select(NAME, STATE_NAME, total_votes, ALAND, voter_density)\n\n\nSimple feature collection with 1 feature and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -90.32052 ymin: 38.53201 xmax: -90.16671 ymax: 38.77429\nGeodetic CRS:  WGS 84\n       NAME STATE_NAME total_votes     ALAND voter_density\n1 St. Louis   Missouri      527644 159853177   0.003300804\n                        geometry\n1 MULTIPOLYGON (((-90.32052 3...\n\n\n\nCounty with the Largest Increase in Voter Turnout in 2024?\n\nMontgomery County, Texas, saw the largest increase in voter turnout from 2020 to 2024, with a remarkable jump of 36,482 votes. This surge indicates growing political engagement, which could reflect a shift in local dynamics or an increased focus on voter outreach and participation efforts. The significant increase in voter turnout could be a key factor in understanding future election trends, particularly in swing states or suburban areas where demographic changes are occurring.\n\n\nShow the code\nturnout_change &lt;- counties_2020_sf |&gt;\n  st_drop_geometry() |&gt;\n  mutate(total_2020 = trump_votes + biden_votes) |&gt;\n  select(NAME, STATE_NAME, total_2020) |&gt;\n  inner_join(\n    counties_2024_sf |&gt;\n      st_drop_geometry() |&gt;\n      mutate(total_2024 = trump_votes + harris_votes) |&gt;\n      select(NAME, STATE_NAME, total_2024),\n    by = c(\"NAME\", \"STATE_NAME\")\n  ) |&gt;\n  mutate(turnout_diff = total_2024 - total_2020) |&gt;\n  slice_max(turnout_diff, n = 1) |&gt;\n  select(NAME, STATE_NAME, total_2020, total_2024, turnout_diff)\n\nprint(turnout_change)\n\n\n        NAME STATE_NAME total_2020 total_2024 turnout_diff\n1 Montgomery      Texas     267759     304241        36482\n\n\n\n\nCounty-Level Shift in Trump Vote Share: 2020 to 2024\nThe county-level shift in Trump’s vote share between 2020 and 2024 reveals significant political changes across the U.S. While rural areas generally show stronger support for Trump, urban and suburban counties are exhibiting slight shifts away from him, indicating evolving political preferences. This trend is especially pronounced in battleground states, signaling that the 2024 election will remain fiercely contested. These shifts, as visualized in the mapped data, suggest a further deepening of partisan divides and a more polarized political landscape.\n\n\nShow the code\n# Task 5, Step1: Computing the shift rightwards for each county\n# Convert the sf objects to data frames before the join\ncounties_2020_df &lt;- counties_2020_sf |&gt;\n  st_drop_geometry() |&gt;\n  select(NAME, STATE_NAME, trump_pct_2020)\n\ncounties_2024_df &lt;- counties_2024_sf |&gt;\n  st_drop_geometry() |&gt;\n  select(NAME, STATE_NAME, trump_pct_2024)\n\n# Perform the join on the data frames\n# First, merge the 2020 and 2024 vote data\ncounty_votes &lt;- counties_2020_df |&gt;\n  inner_join(counties_2024_df, by = c(\"NAME\", \"STATE_NAME\")) |&gt;\n  mutate(\n    shift_pct = trump_pct_2024 - trump_pct_2020\n  )\n\n# Then join the vote data into the sf object\ncounties_sf_combined &lt;- counties_sf |&gt;\n  left_join(county_votes, by = c(\"NAME\", \"STATE_NAME\"))\n\n#Task 5, Step 2: Modifying geometry for Hawaii and Alaska\n# Transform Alaska and Hawaii geometries separately\ncounties_2024_sf &lt;- counties_2024_sf |&gt;\n  mutate(geometry = st_transform(geometry, crs = \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lon_0=-96\"))\n\n# Revert geometries for Alaska and Hawaii to the original ones after transformation\ncounties_2024_sf &lt;- counties_2024_sf |&gt;\n  mutate(\n    geometry = case_when(\n      STATE_NAME == \"Alaska\" ~ geometry,\n      STATE_NAME == \"Hawaii\" ~ geometry,\n      TRUE ~ geometry\n    )\n  )\n#Task 5, Step 3: Draw the Map with Modified Geometry\n# Calculate the shift in Trump percentage (2024 - 2020)\n# After joining 2020 and 2024 data frames and adding the geometry\ncounties_sf_combined &lt;- counties_sf_combined |&gt;\n  mutate(\n    shift_pct = trump_pct_2024 - trump_pct_2020  # Positive values indicate rightward shift\n  )\n\n# Now plot the map with shift_pct\ncounties_sf_combined |&gt;\n  filter(!is.na(shift_pct)) |&gt;\n  ggplot() +\n  geom_sf(aes(fill = shift_pct), color = \"white\", size = 0.1) +\n  scale_fill_gradient2(\n    low = \"#0D52BD\", mid = \"white\", high = \"#d7301f\", midpoint = 0,\n    name = \"Shift in % Trump Vote\"\n  ) +\n  coord_sf(xlim = c(-125, -66), ylim = c(24, 50), expand = FALSE) +\n  labs(\n    title = \"County-Level Shift in Trump Vote Share (2020–2024)\",\n    subtitle = \"Red = rightward shift, Blue = leftward shift\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\"),\n    plot.subtitle = element_text(margin = margin(b = 10))\n  )"
  },
  {
    "objectID": "mp04.html#conclusion",
    "href": "mp04.html#conclusion",
    "title": "Mini-Project #04: Exploring Recent US Political Shifts",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis highlights key shifts in voter behavior between the 2020 and 2024 U.S. presidential elections, with significant changes in both voter turnout and Trump’s support across counties. Notable trends, such as shifts in key battleground counties and increased voter engagement, point to a more polarized political landscape. These insights provide a clearer picture of evolving political dynamics and will be valuable for understanding future election trends."
  }
]